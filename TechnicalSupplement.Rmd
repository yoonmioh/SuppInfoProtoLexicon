---
title: "An Adult Proto-lexicon"
subtitle: "Participant filtering, statistical analysis, plots and tables"
author: "Yoon Mi Oh, Clay Beckner, Simon Todd, Jen Hay, Jeanette King and Jeremy Needle"
date: '`r Sys.time()`'
output:
  html_document:
    fig_caption: yes
    highlight: textmate
    theme: flatly
    toc: yes
    toc_depth: 6
    toc_float: yes
    number_sections: true
  word_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, echo=F, message=F, warning=FALSE}
library(ggplot2)
library(lme4)
library(lmerTest)
library(ndl)
library(effects)
library(plyr)
library(knitr)
library(xtable)
library(ggridges)
library(dplyr)
library(ordinal)
library(MASS)
library(readr)
library(stringr)
```

<style>
caption, .caption {
color: black;
font-size: 90%;
text-align: left}
a[hreflang]:before{}
</style>

```{r local_functions, echo=FALSE}
# Local functions
c. <- function (x) scale(x, scale = FALSE)

multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)
  
  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)
  
  numPlots = length(plots)
  
  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                     ncol = cols, nrow = ceiling(numPlots/cols))
  }
  
  if (numPlots==1) {
    print(plots[[1]])
    
  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
    
    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
      
      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

# A function to format ordinal regression results in a nice table, LaTeX-style
clm_table <- function(mod) {
  coefs.all <- summary(mod)$coefficients
  coefs.thresholds <- data.frame(coefs.all[grepl("\\|", rownames(coefs.all)),])
  coefs.thresholds[,c("z.value", "Pr...z..", "Significance")] <- NA
  coefs.effects <- data.frame(coefs.all[!grepl("\\|", rownames(coefs.all)),])
  coefs.effects$Significance <- with(coefs.effects,
                                   ifelse(Pr...z..<0.001,"***",
                                          ifelse(Pr...z..<0.01,"**",
                                                 ifelse(Pr...z..<0.05,"*",
                                                        ifelse(Pr...z..<0.1,".",
                                                               "")))))  
  coefs.table <- rbind(coefs.effects, coefs.thresholds)
  coefs.table <- cbind(data.frame(Type = c("Effects", rep("", nrow(coefs.effects)-1), "Thresholds", rep("", nrow(coefs.thresholds)-1)), Parameter = rownames(coefs.table)), coefs.table)
  rownames(coefs.table) <- NULL
  names(coefs.table) <- c(" ", "Parameter", "Estimate", "Std. Error", "z.value", "Pr(>|z|)", "")
  return(coefs.table)
}

options(knitr.kable.NA = '')

# A function to add predicted mean ratings from an ordinal regression Effect table, given a set of thresholds
add_predicted_ratings = function(effect_table, threshold_table) {
  effect_table$predicted.mean = sapply(effect_table$fit, 
                                       function(x){return(sum(c(1, plogis(x-threshold_table$threshold))))})
  effect_table$predicted.lower = sapply(effect_table$lower, 
                                       function(x){return(sum(c(1, plogis(x-threshold_table$threshold))))})
  effect_table$predicted.upper = sapply(effect_table$upper, 
                                       function(x){return(sum(c(1, plogis(x-threshold_table$threshold))))})
  return(effect_table)
}
```

# Introduction 
This R Markdown script contains all the code used for outlier detection, data analysis, and plotting. It includes the description for materials, methods, additional statistical analyses, Monte Carlo simulations, and all the statistical models with summaries.

# Experiment 1
## Stimuli
Exp1 (identification task) tests NMS' implicit knowledge of Māori words with varying frequencies. The stimulus materials for the identification task consist of 1,000 Māori words and 1,000 Māori-like nonwords. To obtain a list of words, all words in two Māori running speech data (*32*, *33*) are divided into five frequency bins and 200 words are randomly selected from each of those bins. A list of 10,000 pseudowords (1,000 pseudowords for each phoneme length of nonwords ranging from length 3 to length 12) were generated from a trigram language model by a pseudoword generator (*34*) using a Māori dictionary (*35*) and two running speech corpora (*32, 33*) as training sets. For each word, a nonword is chosen by matching its length and phonotactic score. The phonotactic scores of stimuli are computed using type frequency obtained from a Māori dictionary (*35*). A trigram model is selected in order to take positional information within words into account, including an additional symbol to indicate word boundaries while building a language model. The phonotactic score of each stimulus is obtained by summing log-transformed transitional probabilities which better reflect frequency distributions than raw probabilities (*36*) and then is normalized by length. The Witten-Bell smoothing in SRILM (SRI Language Modeling Toolkit) (*37*) is used to deal with unknown trigrams in nonwords since nonwords are created by training data composed of two RS corpora (*32*, *33*) and a Māori dictionary (*35*), some nonwords contain trigrams which are not observed in a trigram language model built from a dictionary. Every participant had a different list of 300 stimuli containing 30 pairs (words and nonwords) randomly selected from each of five bins (30\*2\*5 = 300 in total). The list of stimuli used in Exp1 can be found in "StimuliExp1.txt".

## Participants
In Exp1, nonfluent Māori speakers based in New Zealand (NMS), 18 years or older, were recruited online by Facebook Ads. Several exclusion criteria were applied to filter out unusable participants in this experiment. All participants speak New Zealand English as their first language. However, nine participants learned English outside New Zealand and among them, we discard one participant who currently lives in New Zealand for less than ten years. Furthermore, based on their answers to the post-questionnaire, two participants whose level of self-reported proficiency of Māori corresponds to at least “fairly well”, two participants with some knowledge of any other Polynesian languages, and five participants who reported a history of any speech or language impairments are removed. Due to a technical error during the experiment, the data of one participant who rated too small number of stimuli is discarded. After removing those outliers, we also look at the pattern of variability in participants' responses and discard one participant whose standard deviation of ratings falls below two times the standard deviation below the mean among participants.

```{r loading_data_Exp1, echo=TRUE, message=FALSE, warning=FALSE}
# Loading the data to filter out participants
dataExp1 <- read.delim("./dataAnonNotFilteredExp1.txt", sep ="\t", header = TRUE)
dataExp1$word = as.character(dataExp1$word)
Encoding(dataExp1$word) = "UTF-8"

# Remove one participant who did 192 items instead of 303
nbResponse <- aggregate(dataExp1$enteredResponse, by=list(dataExp1$workerId),  FUN=length)
rmParticipant1Exp1 <- nbResponse[!nbResponse$x %in% c(303),]$Group.1 # 4c62b407
dataExp1 <- dataExp1[!dataExp1$workerId %in% rmParticipant1Exp1,]

# Remove three participants who gave ratings lower than 4 to 3 most common Māori words borrowed into New Zealand English
list_carrot <- c("haka","kai","aotearoa")
carrots <- dataExp1[dataExp1$word %in% list_carrot,]
carrots <- carrots[as.numeric(carrots$enteredResponse) < 4,]
rmParticipant2Exp1 <- unique(carrots$workerId) # 51aee430 7d4efcd7 15950569
dataExp1 <- dataExp1[!dataExp1$workerId %in% rmParticipant2Exp1,]

# Remove ratings for the three words (used to detect outliers)
dataExp1 <- dataExp1[!dataExp1$word %in% c("haka","kai","aotearoa"),]

# Remove two participants whose speakMaori or compMaori is at least (equal to or above) 3
rmParticipant3Exp1 <- unique(dataExp1[dataExp1$speakMaori >= 3 | dataExp1$compMaori >= 3,]$workerId) # b59cb76f 56496f48
dataExp1 <- dataExp1[!dataExp1$workerId %in% rmParticipant3Exp1,]

# Remove one participant who did not learn their English in NZ and have been living in their current location in NZ for less than ten years (duration == "short")
summaryExp1WorkerId <- unique(dataExp1[,c("workerId","firstLangCountry","place","duration")])
EngNotInNZExp1 <- summaryExp1WorkerId[!summaryExp1WorkerId$firstLangCountry=="NZ",]
rmParticipant4Exp1 <- unique(EngNotInNZExp1[EngNotInNZExp1$duration=="short",]$workerId) # 2fc57ffc
dataExp1 <- dataExp1[!dataExp1$workerId %in% rmParticipant4Exp1,]

# Remove two participants who know any other Polynesian languages
rmParticipant5Exp1 <- unique(dataExp1[dataExp1$anyPolynesian=="Yes",]$workerId) # aa4d5676 2b08d4eb
dataExp1 <- dataExp1[!dataExp1$workerId %in% rmParticipant5Exp1,]

# Remove five participants with language impairments
rmParticipant6Exp1 <- unique(dataExp1[dataExp1$impairments=="Yes",]$workerId) 
# ae48fa46 b589ecc3 367285b5 6ff6dcb6 bcae3239
dataExp1 <- dataExp1[!dataExp1$workerId %in% rmParticipant6Exp1,]

# Remove one participant whose pattern of responses (SD) is below 2SD of the mean of all participants
SD <- aggregate(dataExp1$enteredResponse, by=list(dataExp1$workerId), sd)
cut <- mean(SD$x)-2*sd(SD$x)
rmParticipant7Exp1 <- SD[!SD$x > cut,]$Group.1 # d7a9b857
dataExp1 <- dataExp1[!dataExp1$workerId %in% rmParticipant7Exp1,]

# Check the total number of usable participants for Exp1
# length(unique(dataExp1$workerId)) # 85
```

## Overview of participants’ sociolinguistic profile
Regarding participants' age and highest level of education, the distribution is quite balanced in comparison to their self-reported level of Māori proficiency, current place of living and gender. There are substantially more female participants than male and those living in the North Island than in the South Island. Regarding their sociolinguistic profile in relation to Māori, after filtering out participants who considered their level of Māori proficiency at least as fairly well, most participants self-reported that they had some basic knowledge of Māori and only a few participants responded that their level of exposure to Māori was less than once a year. This figure summarizes the distribution of participants on demographic and linguistic axes.

```{r participantExp1, echo=FALSE, message=FALSE, warning=FALSE, evaluate=FALSE, fig.width=9.5, fig.height=6.5, fig.cap="Fig. S1: Overview of participants' sociolinguistic profile in Exp1."}
# Basic knowledge of Māori
Exp1ML <- unique(dataExp1[,c("maoriList","workerId")]);Exp1ML$maoriList <- as.factor(Exp1ML$maoriList)
Exp1MLT <- as.data.frame(table(Exp1ML$maoriList));names(Exp1MLT) <- c("maoriList","freq")
FigS1Exp1ML <- ggplot(Exp1ML, aes(x=maoriList,color=maoriList,fill=maoriList))+theme_classic()+ geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=Exp1MLT, aes(x=maoriList,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Basic knowledge of Māori",y="Number of participants") + coord_cartesian(ylim=c(0, 20))

# Māori proficiency 
Exp1MP <- unique(dataExp1[,c("maoriProf","workerId")]);Exp1MP$maoriProf <- as.factor(Exp1MP$maoriProf)
Exp1MPT <- as.data.frame(table(Exp1MP$maoriProf));names(Exp1MPT) <- c("maoriProf","freq")
FigS1Exp1MP <- ggplot(Exp1MP, aes(x=maoriProf, color=maoriProf, fill=maoriProf))+theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=Exp1MPT, aes(x=maoriProf,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Māori proficiency",y="Number of participants") + coord_cartesian(ylim=c(0, 60))

# Exposure to Māori
Exp1ME <- unique(dataExp1[,c("maoriExpo","workerId")]);Exp1ME$maoriExpo <- as.factor(Exp1ME$maoriExpo)
Exp1MET <- as.data.frame(table(Exp1ME$maoriExpo));names(Exp1MET) <- c("maoriExpo","freq")
FigS1Exp1ME <- ggplot(Exp1ME, aes(x=maoriExpo, color=maoriExpo, fill=maoriExpo))+theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=Exp1MET, aes(x=maoriExpo,y=freq,label=freq), color="black", vjust=-0.2,size=3)+labs(x="Level of exposure",y="Number of participants") + coord_cartesian(ylim=c(0, 20))

# Gender
Exp1Gender <- unique(dataExp1[,c("gender","workerId")])
Exp1GenderT <- as.data.frame(table(Exp1Gender$gender));names(Exp1GenderT) <- c("gender","freq")
FigS1Exp1Gender <- ggplot(Exp1Gender, aes(x=gender,color=gender,fill=gender)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=Exp1GenderT, aes(x=gender,y=freq,label=freq), color="black", vjust=-0.2,size=3)+labs(x="Gender",y="Number of participants") + coord_cartesian(ylim=c(0, 83))

# Age
Exp1Age <- unique(dataExp1[,c("age","workerId")]);Exp1Age$age <- as.factor(Exp1Age$age)
Exp1Age$age <- factor(Exp1Age$age, levels=c("18-29", "30-39", "40-49", "50-59", "+60"))
Exp1AgeT <- as.data.frame(table(Exp1Age$age));names(Exp1AgeT) <- c("age","freq")
Exp1AgeT$age <- factor(Exp1AgeT$age, levels=c("18-29", "30-39", "40-49", "50-59", "+60"))
FigS1Exp1Age <- ggplot(Exp1Age, aes(x=age,color=age,fill=age))+theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=Exp1AgeT, aes(x=age,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Age",y="Number of participants") + coord_cartesian(ylim=c(0, 23))

# Education
Exp1Education <- unique(dataExp1[,c("education","workerId")]);Exp1Education$education <- as.factor(Exp1Education$education)
Exp1EducationT <- as.data.frame(table(Exp1Education$education));names(Exp1EducationT) <- c("education","freq")
edu_levels <- c("high","undergraduate","graduate")
Exp1Education$education <- factor(Exp1Education$education, levels = edu_levels)
Exp1EducationT$education <- factor(Exp1EducationT$education, levels = edu_levels)
FigS1Exp1Education <- ggplot(Exp1Education, aes(x=education,color=education,fill=education)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=Exp1EducationT, aes(x=education,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Highest education",y="Number of participants") + coord_cartesian(ylim=c(0, 35))

# Place
Exp1Place <- unique(dataExp1[,c("place","workerId")]);Exp1PlaceT <- as.data.frame(table(Exp1Place$place));names(Exp1PlaceT) <- c("place","freq")
place_levels <- c("north","south")
Exp1Place$place <- factor(Exp1Place$place, levels = place_levels)
Exp1PlaceT$place <- factor(Exp1PlaceT$place, levels = place_levels)
FigS1Exp1Place <- ggplot(Exp1Place, aes(x=place, color=place, fill= place)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=Exp1PlaceT,aes(x=place,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x = "Place", y = "Number of participants") + coord_cartesian(ylim=c(0, 65))

multiplot(FigS1Exp1ML, FigS1Exp1Gender, FigS1Exp1Place, FigS1Exp1MP, FigS1Exp1Age, FigS1Exp1Education, FigS1Exp1ME, cols=3)
```

## Dataset structure
The data is structured as follows:

  - *workerId* is the unique ID for each participant.
  - *enteredResponse* is the wellformedness rating for each stimulus.
  - *reactionTime* is the reaction time for each rating (second).
  - *type* is the classification of each stimulus: word ('real') or nonword ('pseudo').
  - *length* is the phoneme length of each stimulus.
  - *word* is the stimulus used for the rating.
  - *speakMaori* is each participant's answer to the question how well they can speak Māori (with a scale ranging from 0 to 5).
  - *compMaori* is each participant's answer to the question how well they can understand/read Māori (with a scale ranging from 0 to 5). 
  - *maoriProf* is the sum of quantified response for speakMaori and compMaori, which refers to the level of each participant's Māori proficiency.
  - *age* is the age group where each participant belongs to .
  - *gender* is the gender of each participant. 
  - *ethnicity* is categorized into binary answers, either Māori (M) or non Māori (non M).
  - *education* is each participant's highest level of education.
  - *children* is each participant's answer to the question whether they have had any children who have attended preschool or primary school in New Zealand in the past five years.
  - *maoriList* is each participant's basic knowledge of Māori (with a scale ranging from 0 to 9).
  - *place* is each participant's current place of living (categorized into binary classification, either North or South Island in New Zealand).
  - *duration* is each participant's time duration of living in their current place (categorized into binary classification, long: > 10 years and short: =< 10 years).
  - *firstLang* is each participant's first language.
  - *firstLangCountry* is the country where each participant learned their first language.  
  - *anyOtherLangs* is the information regarding any other languages each participant can speak.
  - *hawaii* is the binary response to the question whether participants have lived in Hawaii.
  - *anyPolynesian* is the binary response to the question whether participants know any Polynesian such as Hawaiian, Tahitian, Sāmoan, or Tongan.
  - *whichPolynesian* is the information regarding participants' knowledge of any Polynesian languages if they knew any.
  - *impairments* is the answer to the question whether participants have a history of any speech or language impairments.
  - *maoriExpo* is each participant's level of exposure to Māori (with a scale ranging from 0 to 10).
  - *Freq* is the frequency of real word stimulus obtained from Māori running speech corpora (Freq=0 for pseudowords).
  - *bin* is the classification of each stimulus according to their frequency of occurence in Māori running speech corpora.
  - *score* is the phonotactic score obtained across word types in the dictionary.

## NMS confidence ratings across word frequency with ordinal mixed-effects modeling
### Table S1, model summary
```{r Table S1, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE}
# Model for TableS1
dataExp1$enteredResponse <- as.factor(dataExp1$enteredResponse)
helmert <- matrix(c(c(4,-1,-1,-1,-1)/5, c(0,3,-1,-1,-1)/4, c(0,0,2,-1,-1)/3, c(0,0,0,1,-1)/2), ncol=4)
colnames(helmert) <- c("1v2+", "2v3+", "3v4+", "4v5")
dataExp1$bin <- as.factor(dataExp1$bin)
contrasts(dataExp1$bin) <- helmert
# modelTableS1 <- clmm(enteredResponse ~ c.(length)*c.(score) + type*bin + (1 + c.(length)*c.(score) + type*bin|workerId) + (1|word), dataExp1)
# saveRDS(modelTableS1, file = "modelTableS1.rds")
modelTableS1 <- readRDS("./modelTableS1.rds")
kable(clm_table(modelTableS1), digits=3, caption="Table S1: Ordinal mixed-effects model of NMS confidence ratings across word frequency. All numeric variables in this model except for the wellformedness rating are centered.")
```

### Fig. S2, effect plots
```{r Fig. S2, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=3.5, fig.cap="Fig. S2: Interaction effect plots: Fig. S2a (left) shows the interaction between frequency bin and lexicality (real words vs. nonwords); Fig. S2b (right) shows the interaction between phonotactic score and length of stimuli. The bars represent 95% confidence intervals."}
thresholds.S2a <- data.frame(label=names(modelTableS1$alpha), threshold=modelTableS1$alpha, row.names=NULL)

figS2a <- as.data.frame(Effect(c("type", "bin"), modelTableS1, latent=TRUE))
levels(figS2a$type) = c("Nonword", "Word")
figS2a <- add_predicted_ratings(figS2a, thresholds.S2a)

figS2b <- as.data.frame(Effect(c("length", "score"), modelTableS1, xlevels=list(length=c(3,6,9,12)), latent=TRUE))
figS2b <- add_predicted_ratings(figS2b, thresholds.S2a)

RfigS2a <- ggplot(figS2a, aes(x=as.integer(bin), y=predicted.mean, color=type, fill=type, shape=type)) +
  geom_ribbon(aes(ymin=predicted.lower, ymax=predicted.upper), alpha=0.1, color=NA) + 
  geom_line(size=1, alpha=0.4) +
  geom_point(size=4) +
  geom_errorbar(aes(ymin=predicted.lower, ymax=predicted.upper), size=1, width=0.3) +
  xlab("Frequency Bin (High to Low)") +
  ylab("Predicted Mean Rating") + 
  scale_shape_manual(values = c("Nonword" = 19, "Word" = 17)) +   
  theme_classic() + 
  theme(
    plot.title = element_text(hjust = 0.5, size=15),
    legend.position="right",
    legend.title=element_blank())

RfigS2b <- ggplot(figS2b, aes(x=score, y=predicted.mean, color=length, group=length)) +
  geom_ribbon(aes(ymin=predicted.lower, ymax=predicted.upper), alpha=0.1, color=NA) + 
  geom_line(size=1) +
  scale_color_continuous(breaks=c(3,6,9,12), guide = guide_colourbar(title="Length", draw.ulim = FALSE, draw.llim = FALSE)) +
  xlab("Phonotactic score") +
  ylab("Predicted Mean Rating") + 
  theme_classic() + 
  theme(
    plot.title = element_text(hjust = 0.5, size=15),
    legend.position="right")

multiplot(RfigS2a, RfigS2b, cols=2)
```

## Code for plotting Fig. 1 
```{r Fig. 1, echo=FALSE, message=FALSE, warning=FALSE, evaluate=FALSE, fig.width=14, fig.height=5, fig.cap="Fig. 1: Mean well-formedness ratings for real words and nonwords by frequency bin. Bin1 contains the most frequent words and Bin5 consists of the least frequent words. Horizontal lines show mean ratings for real words vs. nonwords per bin."}

#Get mean ratings for each stimulus per bin
allBins <- list()
for(i in 1:5){
Bin <- dataExp1[dataExp1$bin==i,]
BinMeanRatings <- aggregate(as.numeric(Bin$enteredResponse), by=list(Bin$word, Bin$type), mean)
names(BinMeanRatings) <- c("word","type","meanRating")
BinMeanRatings$bin <- paste0("Bin",i)
allBins[[i]] <- BinMeanRatings
}
allBins <- do.call(rbind,allBins)
allBins$type = factor(allBins$type)
levels(allBins$type) = c("Nonword", "Word")

figS2a_mean = allBins %>% group_by(type, bin) %>% summarize(grand_mean = mean(meanRating))

ggplot(allBins,aes(x = bin, y = meanRating, fill = type)) +
    geom_violin(alpha=0.4, position=position_identity()) + 
    labs(y = "Mean Rating (by stimulus)",x = "Frequency Bin") +
    theme_classic() + 
    geom_point(data=figS2a_mean, aes(y=grand_mean, shape=type), size=4) +
    geom_line(data=figS2a_mean, aes(x=as.numeric(as.factor(bin)), y=grand_mean, color=type, linetype=type), size=1) + 
    scale_fill_manual(name="Stimulus type",
                      values = c("Nonword" = "black", "Word" = "blue")) +  
    scale_shape_manual(name="Stimulus type",
                      values = c("Nonword" = 21, "Word" = 24)) +   
    scale_color_manual(name="Effect estimate",
                       values = c("Nonword"="black", "Word" = "blue"),
                       guide=FALSE) +
    scale_linetype_manual(name="Effect estimate",
                          values = c("Nonword" = "solid", "Word" = "dotted"),
                          guide=FALSE)
```

## Mean rating and phonotactic score for each stimulus per frequency bin
```{r Fig. S3, echo=FALSE, message=FALSE, warning=FALSE, fig.width=11, fig.height=6.5, fig.cap="Fig. S3: Mean rating vs. phonotactic score for each stimulus for real words and nonwords by frequency bin."}
scores <- unique(dataExp1[,c("word","score")])

Bin1MeanRatings <- merge(allBins[allBins$bin=="Bin1",], scores, by="word")
FigS3Bin1 <- ggplot(Bin1MeanRatings, aes(x=score, y=meanRating, color=type, shape=type, label=word)) + 
  labs(x= "Phonotactic score (Bin 1)", y="Mean rating") + 
  theme_classic()+ 
  geom_point(size=2) + 
  scale_colour_manual(values=c("#F8766D", "#00BFC4")) + 
  theme(
    legend.position="bottom",
    legend.title=element_blank())

Bin2MeanRatings <- merge(allBins[allBins$bin=="Bin2",], scores, by="word")
FigS3Bin2 <- ggplot(Bin2MeanRatings, aes(x=score, y=meanRating, color=type, shape=type, label=word)) + 
  labs(x= "Phonotactic score (Bin 2)", y="Mean rating") + 
  theme_classic() + 
  geom_point(size=2) + 
  scale_colour_manual(values=c("#F8766D", "#00BFC4")) + 
  theme(
    legend.position="bottom",
    legend.title=element_blank())

Bin3MeanRatings <- merge(allBins[allBins$bin=="Bin3",], scores, by="word")
FigS3Bin3 <- ggplot(Bin3MeanRatings, aes(x=score, y=meanRating, color=type, shape=type, label=word)) + 
  labs(x= "Phonotactic score (Bin 3)", y="Mean rating") + 
  theme_classic() + 
  geom_point(size=2)+ 
  scale_colour_manual(values=c("#F8766D", "#00BFC4")) + 
  theme(
    legend.position="bottom",
    legend.title=element_blank())

Bin4MeanRatings <- merge(allBins[allBins$bin=="Bin4",], scores, by="word")
FigS3Bin4 <- ggplot(Bin4MeanRatings, aes(x=score, y=meanRating, color=type, shape=type, label=word)) + 
  labs(x= "Phonotactic score (Bin 4)", y="Mean rating") + 
  theme_classic() + 
  geom_point(size=2) + 
  scale_colour_manual(values=c("#F8766D", "#00BFC4")) + 
  theme(
    legend.position="bottom",
    legend.title=element_blank())

Bin5MeanRatings <- merge(allBins[allBins$bin=="Bin5",], scores, by="word")
FigS3Bin5 <- ggplot(Bin5MeanRatings, aes(x=score, y=meanRating, color=type, shape=type, label=word)) + 
  labs(x= "Phonotactic score (Bin 5)", y="Mean rating") + 
  theme_classic() + 
  geom_point(size=2) + 
  scale_colour_manual(values=c("#F8766D", "#00BFC4")) + 
  theme(
    legend.position="bottom",
    legend.title=element_blank())

multiplot(FigS3Bin1,FigS3Bin4,FigS3Bin2,FigS3Bin5,FigS3Bin3, cols=3)
```

## Rematching stimuli pairs

During the analysis of Exp1, we found an overall bias towards higher phonotactic scores of Māori words and lower phonotactic score of Māori-like nonwords (see Fig. S3). This pattern is caused by a lack of nonwords which phonotactically matched the randomly selected words from the Māori RS corpora. To solve this problem, nonwords and words are rematched across participants by finding a phonotactically matched word with the lowest absolute difference for each nonword. Among the rematched pairs, only those whose absolute difference is below 0.1 are kept. In the initial dataset, there are 200 pairs in each bin. After rematching stimuli, the number of pairs in each bin is reduced as follows: 60 (Bin1), 38 (Bin2), 39 (Bin3), 46 (Bin4), 43 (Bin5).

### Rematched pairs: mean rating and phonotactic score for each stimulus per frequency bin
```{r Fig. S4, echo=FALSE, message=FALSE, warning=FALSE, fig.width=11, fig.height=6.5, fig.cap="Fig. S4: Mean rating and phonotactic score for each stimulus per frequency bin (rematched pairs)."}

# Rematching pairs: for each nonword, find a word with the lowest absolute difference
dataPseudo <- dataExp1[dataExp1$type=="pseudo",]
listPseudo <- unique(dataPseudo[,c("word","score","length")])
colnames(listPseudo)[1] <- "pseudo"
listPseudo <- listPseudo[order(listPseudo$score, decreasing=TRUE),]
dataReal <- dataExp1[dataExp1$type=="real",]
listReal <- unique(dataReal[,c("word","score","length","bin")])

ListPseudoLength <- list()
for(i in 3:12){
listPseudoLength <- listPseudo[listPseudo$length==i,]
listRealLength <- listReal[listReal$length==i,]
ListPseudoPair <- list()
for(j in 1:nrow(listPseudoLength)){
real_word <- listRealLength[which.min(abs(listPseudoLength$score[j] - listRealLength$score)),]
listRealLength <- listRealLength[!(listRealLength$word %in% real_word$word),]
ListPseudoPair[[j]] <- real_word$word
}
ListPseudoPairs <- as.data.frame(unlist(ListPseudoPair))
listPseudoLength$word <- unlist(ListPseudoPairs)
listPseudoLength <- merge(listPseudoLength, listReal, by="word")
listPseudoLength$diff <- round(listPseudoLength$score.x - listPseudoLength$score.y, digits=6)
listPseudoLength <- listPseudoLength[abs(listPseudoLength$diff) < 0.10,] 
ListPseudoLength[[j]] <- listPseudoLength
}
ListAll <- do.call("rbind", ListPseudoLength)
ListAllReal <- ListAll[,c("word","score.y","length.x","bin")]
names(ListAllReal) <- c("word","score","length","bin");ListAllReal$type <- "real"
ListAllPseudo <- ListAll[,c("pseudo","score.x","length.x","bin")]
names(ListAllPseudo) <- c("word","score","length","bin");ListAllPseudo$type <- "pseudo"
dataReal <- dataReal[,c("word","enteredResponse","workerId")]
dataPseudo <- dataPseudo[,c("word","enteredResponse","workerId")]
ListAllReal <- merge(ListAllReal, dataReal, by="word")
ListAllPseudo <- merge(ListAllPseudo, dataPseudo, by="word")
dataRematched <- rbind(ListAllReal,ListAllPseudo)

scores <- unique(dataExp1[,c("word","score")])
dataRematched$enteredResponse <- as.numeric(dataRematched$enteredResponse)
Bin1Re <- dataRematched[dataRematched$bin==1,]
Bin1ReMeanRatings <- aggregate(Bin1Re$enteredResponse, by=list(Bin1Re$word, Bin1Re$type), mean)
names(Bin1ReMeanRatings) <- c("word","type","meanRating")
Bin1ReMeanRatings <- merge(Bin1ReMeanRatings, scores, by="word")
Bin1ReMeanRatings$Type <- "Word";Bin1ReMeanRatings[Bin1ReMeanRatings$type=="pseudo",]$Type <- "Nonword"
FigS4Bin1 <- ggplot(Bin1ReMeanRatings, aes(x=score, y=meanRating, group=Type, label=word)) + labs(x= "Phonotactic score (Bin 1)", y="Average rating") + theme_classic()+ theme(legend.title=element_blank()) + geom_point(aes(color=Type,shape=Type),size=2)+ scale_colour_manual(values=c("#F8766D", "#00BFC4")) + theme(legend.position="bottom")

Bin2Re <- dataRematched[dataRematched$bin==2,]
Bin2ReMeanRatings <- aggregate(Bin2Re$enteredResponse, by=list(Bin2Re$word, Bin2Re$type), mean)
names(Bin2ReMeanRatings) <- c("word","type","meanRating")
Bin2ReMeanRatings <- merge(Bin2ReMeanRatings, scores, by="word")
Bin2ReMeanRatings$Type <- "Word";Bin2ReMeanRatings[Bin2ReMeanRatings$type=="pseudo",]$Type <- "Nonword"
FigS4Bin2 <- ggplot(Bin2ReMeanRatings, aes(x=score, y=meanRating, group=Type, label=word)) + labs(x= "Phonotactic score (Bin 2)", y="Average rating") + theme_classic()+ theme(legend.title=element_blank()) + geom_point(aes(color=Type,shape=Type),size=2)+ scale_colour_manual(values=c("#F8766D", "#00BFC4")) + theme(legend.position="bottom")

Bin3Re <- dataRematched[dataRematched$bin==3,]
Bin3ReMeanRatings <- aggregate(Bin3Re$enteredResponse, by=list(Bin3Re$word, Bin3Re$type), mean)
names(Bin3ReMeanRatings) <- c("word","type","meanRating")
Bin3ReMeanRatings <- merge(Bin3ReMeanRatings, scores, by="word")
Bin3ReMeanRatings$Type <- "Word";Bin3ReMeanRatings[Bin3ReMeanRatings$type=="pseudo",]$Type <- "Nonword"
FigS4Bin3 <- ggplot(Bin3ReMeanRatings, aes(x=score, y=meanRating, group=Type, label=word)) + labs(x= "Phonotactic score (Bin 3)", y="Average rating") + theme_classic()+ theme(legend.title=element_blank()) + geom_point(aes(color=Type,shape=Type),size=2)+ scale_colour_manual(values=c("#F8766D", "#00BFC4")) + theme(legend.position="bottom")

Bin4Re <- dataRematched[dataRematched$bin==4,]
Bin4ReMeanRatings <- aggregate(Bin4Re$enteredResponse, by=list(Bin4Re$word, Bin4Re$type), mean)
names(Bin4ReMeanRatings) <- c("word","type","meanRating")
Bin4ReMeanRatings <- merge(Bin4ReMeanRatings, scores, by="word")
Bin4ReMeanRatings$Type <- "Word";Bin4ReMeanRatings[Bin4ReMeanRatings$type=="pseudo",]$Type <- "Nonword"
FigS4Bin4 <- ggplot(Bin4ReMeanRatings, aes(x=score, y=meanRating, group=Type, label=word)) + labs(x= "Phonotactic score (Bin 4)", y="Average rating") + theme_classic()+ theme(legend.title=element_blank()) + geom_point(aes(color=Type,shape=Type),size=2)+ scale_colour_manual(values=c("#F8766D", "#00BFC4")) + theme(legend.position="bottom")
 
Bin5Re <- dataRematched[dataRematched$bin==5,]
Bin5ReMeanRatings <- aggregate(Bin5Re$enteredResponse, by=list(Bin5Re$word, Bin5Re$type), mean)
names(Bin5ReMeanRatings) <- c("word","type","meanRating")
Bin5ReMeanRatings <- merge(Bin5ReMeanRatings, scores, by="word")
Bin5ReMeanRatings$Type <- "Word";Bin5ReMeanRatings[Bin5ReMeanRatings$type=="pseudo",]$Type <- "Nonword"
FigS4Bin5 <- ggplot(Bin5ReMeanRatings, aes(x=score, y=meanRating, group=Type, label=word)) + labs(x= "Phonotactic score (Bin 5)", y="Average rating") + theme_classic()+ theme(legend.title=element_blank()) + geom_point(aes(color=Type,shape=Type),size=2)+ scale_colour_manual(values=c("#F8766D", "#00BFC4")) + theme(legend.position="bottom")
 
multiplot(FigS4Bin1,FigS4Bin4,FigS4Bin2,FigS4Bin5,FigS4Bin3, cols=3)
```

### NMS confidence ratings with ordinal mixed-effects model (rematched pairs)
```{r Table S2, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE}
# Model for Table S2
dataRematched$enteredResponse <- as.factor(dataRematched$enteredResponse)
helmert <- matrix(c(c(4,-1,-1,-1,-1)/5, c(0,3,-1,-1,-1)/4, c(0,0,2,-1,-1)/3, c(0,0,0,1,-1)/2), ncol=4)
colnames(helmert) <- c("1v2+", "2v3+", "3v4+", "4v5")
dataRematched$bin <- as.factor(dataRematched$bin)
contrasts(dataRematched$bin) <- helmert
# modelTableS2 <- clmm(enteredResponse ~ c.(score) + type*bin + (1 + c.(score) + type*bin |workerId) + (1|word), dataRematched) 
# saveRDS(modelTableS2, file = "modelTableS2.rds")
modelTableS2 <- readRDS("./modelTableS2.rds")
kable(clm_table(modelTableS2), digits=3, caption="Table S2: Ordinal mixed-effects model of NMS confidence ratings (for rematched pairs).")
```

Within each frequency bin containing the rematched pairs, the distinction between nonwords and words is statistically significant in separate ordinal mixed-effects models for each bin: NMS give higher ratings to words than nonwords across all the bins, except for bin1. When the ratings of all the bins are modeled in a single ordinal mixed-effects model, phonotactic score and the distinction between words and nonwords are significant predictors. This result demonstrates that NMS' ability to distinguish between words and nonwords is not an artefact of their phonotactic knowledge.

# Experiment 2
## Stimuli
The stimulus materials for Exp2 (well-formedness task), comprise of a list of 240 or 320 Māori-like nonwords generated from a trigram model using a pseudoword generator (*34*). About 6,000 pseudowords (1,000 pseudowords for each phoneme length of pseudowords ranging from length 3 to length 8) were generated by using a Māori dictionary (*35*) and two running speech (RS) corpora (*32*,*33*). Nonwords are chosen by decorrelating their phonotactic scores. The phonotactic scores of nonwords are computed using a trigram language model obtained from a Māori dictionary (*35*) and token frequency from segmented two RS data (*32*, *33*), and from unsegmented RS data. The phonotactic score of each stimulus is obtained by summing log-transformed transitional probabilities which better reflect frequency distributions than raw probabilities (*36*) and then is normalized by length. After decorrelating the three types of phonotactic scores, 240 stimuli are chosen for a list of shorter phoneme length (3 and 4) and 320 stimuli for a list of longer phoneme length (5, 6, 7 and 8). In total, there are six lists with either 240 or 320 nonwords of the same phoneme length which are presented in a different random order. The experiment is designed this way in order not to include any additional influence from the length of stimuli. The list of stimuli used in Exp2 can be found in "StimuliExp2.txt".

## Participants
In Exp2, there are three groups of participants: Fluent Māori speakers (MS), non-Māori-speaking speakers of New Zealand English (NMS), and non-Māori-speaking speakers of American English (US). MS and NMS were recruited online by Facebook Ads and US were recruited online by Amazon Mechanical Turk. Participants are adults (18 years or older) who did not previously study linguistics. Most of NMS speak New Zealand English as their first language but 12 participants who did not learn their English in New Zealand but have been living there for at least 10 years are regarded as NMS. On the other hand, 10 participants who learned English outside New Zealand but currently live in New Zealand for less than ten years are discarded. All US speak American English as their first language and one participant who learned English outside the United States is discarded.

In addition to participants' first language, multiple criteria are applied to detect unusable participants. For MS, two participants whose self-reported proficiency level of Māori corresponding to either “no more than a few words or phrases” or “not very well” in their post-questionnaire (below the score of 6) are discarded. For NMS, 14 participants who indicated their proficiency level of Māori as “fairly well”, “well”, or “very well” (above the score of 4) are removed. Among them, the data of five participants whose proficiency level of Māori corresponds to at least “fairly well” (equal to or above the score of 6) are imported to MS. For US, 14 participants who reported a certain proficiency level of Māori and six participants with some basic knowledge of Māori are discarded. For NMS and US, we also discard eight participants who have lived in Hawaii and have some knowledge of any other Polynesian languages such as Hawaiian, Tahitian, Tongan, and Samoan, since any knowledge of those languages belonging to the same language family as Māori may influence participants' well-formedness judgements. However, these criteria are not applied to MS. Among all groups, five participants who reported a history of any speech or language impairments are removed.

The experiment setting for MS and NMS in New Zealand allows us to detect participants using the same browser and within each group, two participants are detected. However, after examining their data, these participants are kept as they do not look suspicious and can be identified as different participants based on their responses to the post-questionnaire. Furthermore, due to a technical error during the experiment, the data of two participants who rated too small or large number of stimuli are discarded.

After removing unusable participants, there are 40 MS, 113 NMS and 94 US. At the initial stage of filtering, 140 participants who did not complete the entire task in Experiment 2 are removed. We also filter out participants who rated items with phoneme length longer than 8 (i.e. 9 and 10 in MS and 9 in NMS) while running the experiment. This decision was made due to a very high rate of uncompleted experiment and the difficulty of recruiting participants for longer lengths such as 9 and 10. We also look at the pattern of participants' response variability within each group and discard one participant in MS, four participants in NMS, and one participant in US whose standard deviation of responses falls below two times the standard deviation below the mean within each group and discard one participant in NMS whose median of reaction time per stimulus is shorter than two times the standard deviation below the mean within the group.

```{r loading_data_Exp2, echo=TRUE, message=FALSE, warning=FALSE}
# Loading the data to filter out participants:
dataNotFiltered <- read.delim("./dataAnonNotFilteredExp2.txt", sep ="\t", header = TRUE)
dataNotFiltered$word = as.character(dataNotFiltered$word)
Encoding(dataNotFiltered$word) = "UTF-8"

# Part 1: Removing unusable MS participants
dataMS <- dataNotFiltered[dataNotFiltered$group=="MS",]

# Remove one participant who did 285 items instead of 320 (length 5)
nbResponse <- aggregate(dataMS$enteredResponse, by=list(dataMS$workerId),  FUN=length)
rmParticipant1 <- nbResponse[!nbResponse$x %in% c(320,240),]$Group.1 # b7619945
dataMS <- dataMS[!dataMS$workerId %in% rmParticipant1,]

# Remove two participants whose speakMaori or compMaori is below 3
rmParticipant2 <- unique(dataMS[dataMS$speakMaori <3 | dataMS$compMaori < 3,]$workerId) 
# 1544dbf9 c4d7bd69
dataMS <- dataMS[!dataMS$workerId %in% rmParticipant2,]

# Remove one participant with language impairments
rmParticipant3 <- unique(dataMS[dataMS$impairments=="Yes",]$workerId) # 7fae7c22
dataMS <- dataMS[!dataMS$workerId %in% rmParticipant3,]

# Detect participants whose median reactionTime is shorter than 2*SD below the mean of all MS
median_RT <- aggregate(dataMS$reactionTime, by=list(dataMS$workerId), median)
names(median_RT) <- c("workerId","median");dataMS <- merge(dataMS,median_RT,by="workerId")
cut <- mean(median_RT$median)-2*sd(median_RT$median)
# median_RT[!median_RT$median > cut,]$workerId # None detected!

# Remove one participant whose pattern of responses (SD) is below 2SD of the mean of all MS participants
SD <- aggregate(dataMS$enteredResponse, by=list(dataMS$workerId), sd)
cut <- mean(SD$x)-2*sd(SD$x)
rmParticipant4 <- SD[!SD$x > cut,]$Group.1 # 379bf450
dataMS <- dataMS[!dataMS$workerId %in% rmParticipant4,]

# Check the total number of usable MS participants
# length(unique(dataMS$workerId)) #40

# Part 2: Removing unusable NMS participants
dataNMS <- dataNotFiltered[dataNotFiltered$group=="NMS",]

# Remove one participant who did 436 items instead of 240 (length 4)
nbResponse <- aggregate(dataNMS$enteredResponse, by=list(dataNMS$workerId),  FUN=length)
rmParticipant5 <- nbResponse[!nbResponse$x %in% c(320,240),]$Group.1 # 10c02fd0
dataNMS <- dataNMS[!dataNMS$workerId %in% rmParticipant5,]

# Remove fourteen participants whose speakMaori or compMaori is at least (equal to or above) 3
rmParticipant6 <- unique(dataNMS[dataNMS$speakMaori >= 3 | dataNMS$compMaori >= 3,]$workerId)  # 13076185 fa784dba 3cde3d04 dab57fd5 a9695b3e 945a57c8 8c51cdc1 930984af 61dd030b 3efd81e0 8f889ddc 379bf450 91950415 72d13b4e
dataNMS <- dataNMS[!dataNMS$workerId %in% rmParticipant6,]

# Remove ten participants who did not learn their English in NZ and have been living in their current location in NZ for less than ten years (duration == "short")
summaryNMSWorkerId <- unique(dataNMS[,c("workerId","firstLangCountry","place","duration")])
EngNotInNZ <- summaryNMSWorkerId[!summaryNMSWorkerId$firstLangCountry=="NZ",]
rmParticipant7 <- unique(EngNotInNZ[EngNotInNZ$duration=="short",]$workerId) # 8332d72f 70dafe1e 4f8b6f05 d3083fc5 e53ac07a 17f67c54 8277a12b 6a1740c7 29d42922 9a7885b3
dataNMS <- dataNMS[!dataNMS$workerId %in% rmParticipant7,]

#Remove one participant who has lived in Hawaii
rmParticipant8 <- unique(dataNMS[dataNMS$hawaii=="Yes",]$workerId) # fc35cab1
dataNMS <- dataNMS[!dataNMS$workerId %in% rmParticipant8,]

# Remove four participants who know any other Polynesian languages
rmParticipant9 <- unique(dataNMS[dataNMS$anyPolynesian=="Yes",]$workerId) # f7466ae0 519ab1a7 a8ef4bcb bdabfcc5
dataNMS <- dataNMS[!dataNMS$workerId %in% rmParticipant9,]

# Remove three participants with language impairments
rmParticipant10 <- unique(dataNMS[dataNMS$impairments=="Yes",]$workerId) # 8e8c19fe 55d7e82a fc8d6ce1
dataNMS <- dataNMS[!dataNMS$workerId %in% rmParticipant10,]

#Remove one participant whose median reactionTime is shorter than 2*SD below the mean of all NMS
median_RT <- aggregate(dataNMS$reactionTime, by=list(dataNMS$workerId), median)
names(median_RT) <- c("workerId","median");dataNMS <- merge(dataNMS,median_RT,by="workerId")
cut <- mean(median_RT$median)-2*sd(median_RT$median)
rmParticipant11 <- median_RT[!median_RT$median > cut,]$workerId # 4b1aac09
dataNMS <- dataNMS[!dataNMS$workerId %in% rmParticipant11,]

# Remove four participants whose pattern of responses (SD) is below 2SD of the mean of all NMS participants
SD <- aggregate(dataNMS$enteredResponse, by=list(dataNMS$workerId), sd)
cut <- mean(SD$x)-2*sd(SD$x)
rmParticipant12 <- SD[!SD$x > cut,]$Group.1 # 3bd22196 4f737f51 6889ff72 98590568
dataNMS <- dataNMS[!dataNMS$workerId %in% rmParticipant12,]

# Check the total number of usable NMS participants
# length(unique(dataNMS$workerId)) #113

# Part3: Removing unusable US participants
dataUS <- dataNotFiltered[dataNotFiltered$group=="US",]

# Remove one participant who did 248 items instead of 240 (length 3)
nbResponse <- aggregate(dataUS$enteredResponse, by=list(dataUS$workerId),  FUN=length)
rmParticipant13 <- nbResponse[!nbResponse$x %in% c(320,240),]$Group.1 # 9198e3ed
dataUS <- dataUS[!dataUS$workerId %in% rmParticipant13,]

# Remove fourteen participants whose speakMaori or compMaori is above 0
rmParticipant14 <- unique(dataUS[dataUS$speakMaori > 0 | dataUS$compMaori > 0,]$workerId)  # 5621e137 da8aa1c2 76e49a1d 20a0b59d cd213e66 a0d0f317 349460f3 78e9bed5 8fcb2f09 84975d69 73c79807 ec169941 7c487108 89bf37e6
dataUS <- dataUS[!dataUS$workerId %in% rmParticipant14,]

# Remove six participants whose maoriList is above 0
rmParticipant15 <- unique(dataUS[dataUS$maoriList > 0,]$workerId) # 5d404970 b40035cc 7233c727 30f0793a 01446e83 c3d73f11
dataUS <- dataUS[!dataUS$workerId %in% rmParticipant15,]

# Remove one participant who did not learn English in the US
rmParticipant16 <- unique(dataUS[!dataUS$firstLangCountry=="US",]$workerId) # c7b992cc
dataUS <- dataUS[!dataUS$workerId %in% rmParticipant16,]

#Remove three participants who have been to Hawaii
rmParticipant17 <- unique(dataUS[dataUS$hawaii=="Yes",]$workerId) # d7464dfa a507847e 6f8cf2ef
dataUS <- dataUS[!dataUS$workerId %in% rmParticipant17,]

#Remove one participant with language impairments
rmParticipant18 <- unique(dataUS[dataUS$impairments=="Yes",]$workerId) # 328bd924
dataUS <- dataUS[!dataUS$workerId %in% rmParticipant18,]

# Detect participants whose median reactionTime is shorter than 2*SD below the mean of all US
median_RT <- aggregate(dataUS$reactionTime, by=list(dataUS$workerId), median)
names(median_RT) <- c("workerId","median");dataUS <- merge(dataUS,median_RT,by="workerId")
cut <- mean(median_RT$median)-2*sd(median_RT$median)
# median_RT[!median_RT$median > cut,]$workerId # None detected!

# Remove one participant whose pattern of responses (SD) is below 2SD of the mean of all US participants
SD <- aggregate(dataUS$enteredResponse, by=list(dataUS$workerId), sd)
cut <- mean(SD$x)-2*sd(SD$x)
rmParticipant19 <- SD[!SD$x > cut,]$Group.1 # 7960174b
dataUS <- dataUS[!dataUS$workerId %in% rmParticipant19,]

# Check the total number of usable US participants
# length(unique(dataUS$workerId)) #94
dataExp2 <- rbind.fill(dataMS, dataNMS, dataUS)
```

## Overview of participants' profile
Regarding participants’ gender, there are substantially more female than male participants in MS and NMS while the gender distribution is quite balanced in US. The distribution of participants' age is also particularly disproportionate in MS and NMS, exhibiting more participants in younger groups. Regarding participants' highest level of education, there are more high school graduates than undergraduates and graduates in MS whereas there are more undergraduates in NMS and US. We only asked MS and NMS to provide their geographical information in New Zealand and self-report their level of exposure to Māori in daily life. There are more participants from the North Island in both MS and NMS due to a large number of population in the North Island. The level of exposure to Māori ranges from 2 (“less than once a year”) to 10 (“multiple times a day”) and the distribution of participants' level of exposure reveals that most of MS are very frequently exposed to Māori in daily life and only a very small number of both MS and NMS are exposed to Māori less than once a year.

```{r Fig. S5, echo=FALSE, message=FALSE, warning=FALSE, fig.width=9.5, fig.height=4.5, fig.cap="Fig. S5: Participants' basic Māori knowledge and proficiency in Exp2."}
# MS - Basic knowledge of Māori
MSML <- unique(dataMS[,c("maoriList","workerId")]);MSML$maoriList <- as.factor(MSML$maoriList)
MSMLT <- as.data.frame(table(MSML$maoriList));names(MSMLT) <- c("maoriList","freq")
FigS5MSML <- ggplot(MSML, aes(x=maoriList,color=maoriList,fill=maoriList)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=MSMLT, aes(x=maoriList,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Basic knowledge of Māori (MS)",y="Number of participants") + coord_cartesian(ylim=c(0, 40))

# NMS - Basic knowledge of Māori
NMSML <- unique(dataNMS[,c("maoriList","workerId")]);NMSML$maoriList <- as.factor(NMSML$maoriList)
NMSMLT <- as.data.frame(table(NMSML$maoriList));names(NMSMLT) <- c("maoriList","freq")
FigS5NMSML <- ggplot(NMSML, aes(x=maoriList,color=maoriList,fill=maoriList)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=NMSMLT, aes(x=maoriList,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Basic knowledge of Māori (NMS)",y="Number of participants") + coord_cartesian(ylim=c(0, 25))

# US - Basic knowledge of Māori
USML <- unique(dataUS[,c("maoriList","workerId")]);USML$maoriList <- as.factor(USML$maoriList)
USMLT <- as.data.frame(table(USML$maoriList));names(USMLT) <- c("maoriList","freq")
FigS5USML <- ggplot(USML, aes(x=maoriList,color=maoriList,fill=maoriList)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=USMLT, aes(x=maoriList,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Basic knowledge of Māori (US)",y="Number of participants") + coord_cartesian(ylim=c(0, 100))

# MS - MaoriProf
MSMP <- unique(dataMS[,c("maoriProf","workerId")]);MSMP$maoriProf <- as.factor(MSMP$maoriProf)
MSMPT <- as.data.frame(table(MSMP$maoriProf));names(MSMPT) <- c("maoriProf","freq")
FigS5MSMP <- ggplot(MSMP, aes(x=maoriProf,color=maoriProf,fill=maoriProf)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=MSMPT, aes(x=maoriProf,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Māori proficiency (MS)",y="Number of participants") + coord_cartesian(ylim=c(0, 25))

# NMS - MaoriProf
NMSMP <- unique(dataNMS[,c("maoriProf","workerId")]);NMSMP$maoriProf <- as.factor(NMSMP$maoriProf)
NMSMPT <- as.data.frame(table(NMSMP$maoriProf));names(NMSMPT) <- c("maoriProf","freq")
FigS5NMSMP <- ggplot(NMSMP, aes(x=maoriProf,color=maoriProf,fill=maoriProf)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=NMSMPT, aes(x=maoriProf,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Māori proficiency (NMS)",y="Number of participants") + coord_cartesian(ylim=c(0, 70))

# US - MaoriProf
USMP <- unique(dataUS[,c("maoriProf","workerId")]);USMP$maoriProf <- as.factor(USMP$maoriProf)
USMPT <- as.data.frame(table(USMP$maoriProf));names(USMPT) <- c("maoriProf","freq")
FigS5USMP <- ggplot(USMP, aes(x=maoriProf,color=maoriProf,fill=maoriProf)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=USMPT, aes(x=maoriProf,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Māori proficiency (US)",y="Number of participants") + coord_cartesian(ylim=c(0, 100))

multiplot(FigS5MSML, FigS5MSMP, FigS5NMSML, FigS5NMSMP, FigS5USML, FigS5USMP, cols=3)
```

```{r Fig. S6, echo=FALSE, message=FALSE, warning=FALSE, fig.width=9.5, fig.height=6.5, fig.cap="Fig. S6: Overview of participants' profile in Exp2."}
# MS - Gender
MSgender <- unique(dataMS[,c("gender","workerId")]);MSgender$gender <- as.factor(MSgender$gender)
MSgenderT <- as.data.frame(table(MSgender$gender));names(MSgenderT) <- c("gender","freq")
FigS6MSgender <- ggplot(MSgender, aes(x=gender,color=gender,fill=gender)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=MSgenderT, aes(x=gender,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Gender (MS)",y="Number of participants") + coord_cartesian(ylim=c(0, 40)) 

# NMS - Gender
NMSgender <- unique(dataNMS[,c("gender","workerId")]);NMSgender$gender <- as.factor(NMSgender$gender)
NMSgenderT <- as.data.frame(table(NMSgender$gender));names(NMSgenderT) <- c("gender","freq")
FigS6NMSgender <- ggplot(NMSgender, aes(x=gender,color=gender,fill=gender)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=NMSgenderT, aes(x=gender,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Gender (NMS)",y="Number of participants") + coord_cartesian(ylim=c(0, 110)) 

# US - Gender
USgender <- unique(dataUS[,c("gender","workerId")]);USgender$gender <- as.factor(USgender$gender)
USgenderT <- as.data.frame(table(USgender$gender));names(USgenderT) <- c("gender","freq")
FigS6USgender <- ggplot(USgender, aes(x=gender,color=gender,fill=gender)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=USgenderT, aes(x=gender,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Gender (US)",y="Number of participants") + coord_cartesian(ylim=c(0, 55)) 

# MS - Age
MSage <- unique(dataMS[,c("age","workerId")]);MSage$age <- as.factor(MSage$age)
MSage$age <- factor(MSage$age, levels=c("18-29", "30-39", "40-49", "50-59", "+60"))
MSageT <- as.data.frame(table(MSage$age));names(MSageT) <- c("age","freq")
MSageT$age <- factor(MSageT$age, levels=c("18-29", "30-39", "40-49", "50-59", "+60"))
FigS6MSage <- ggplot(MSage, aes(x=age,color=age,fill=age)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=MSageT, aes(x=age,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Age (MS)",y="Number of participants") + coord_cartesian(ylim=c(0, 25))

# NMS - Age
NMSage <- unique(dataNMS[,c("age","workerId")]);NMSage$age <- as.factor(NMSage$age)
NMSage$age <- factor(NMSage$age, levels=c("18-29", "30-39", "40-49", "50-59", "+60"))
NMSageT <- as.data.frame(table(NMSage$age));names(NMSageT) <- c("age","freq")
NMSageT$age <- factor(NMSageT$age, levels=c("18-29", "30-39", "40-49", "50-59", "+60"))
FigS6NMSage <- ggplot(NMSage, aes(x=age,color=age,fill=age)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=NMSageT, aes(x=age,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Age (NMS)",y="Number of participants") + coord_cartesian(ylim=c(0, 65))

# US - Age
USage <- unique(dataUS[,c("age","workerId")]);USage$age <- as.factor(USage$age)
USage$age <- factor(USage$age, levels=c("18-29", "30-39", "40-49", "50-59", "+60"))
USageT <- as.data.frame(table(USage$age));names(USageT) <- c("age","freq")
USageT$age <- factor(USageT$age, levels=c("18-29", "30-39", "40-49", "50-59", "+60"))
FigS6USage <- ggplot(USage, aes(x=age,color=age,fill=age)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=USageT, aes(x=age,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Age (US)",y="Number of participants") + coord_cartesian(ylim=c(0, 35))

# MS - Education
MSeducation <- unique(dataMS[,c("education","workerId")]);MSeducation$education <- as.factor(MSeducation$education)
MSeducationT <- as.data.frame(table(MSeducation$education));names(MSeducationT) <- c("education","freq")
edu_levels <- c("high","undergraduate","graduate")
MSeducation$education <- factor(MSeducation$education, levels = edu_levels)
MSeducationT$education <- factor(MSeducationT$education, levels = edu_levels)
FigS6MSeducation <- ggplot(MSeducation, aes(x=education,color=education,fill=education)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=MSeducationT, aes(x=education,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Highest education (MS)",y="Number of participants") + coord_cartesian(ylim=c(0, 20))

# NMS - Education
NMSeducation <- unique(dataNMS[,c("education","workerId")]);NMSeducation$education <- as.factor(NMSeducation$education)
NMSeducationT <- as.data.frame(table(NMSeducation$education));names(NMSeducationT) <- c("education","freq")
edu_levels <- c("high","undergraduate","graduate")
NMSeducation$education <- factor(NMSeducation$education, levels = edu_levels)
NMSeducationT$education <- factor(NMSeducationT$education, levels = edu_levels)
FigS6NMSeducation <- ggplot(NMSeducation, aes(x=education,color=education,fill=education)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=NMSeducationT, aes(x=education,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Highest education (NMS)",y="Number of participants") + coord_cartesian(ylim=c(0, 50))

# US - Education
USeducation <- unique(dataUS[,c("education","workerId")]);USeducation$education <- as.factor(USeducation$education)
USeducationT <- as.data.frame(table(USeducation$education));names(USeducationT) <- c("education","freq")
edu_levels <- c("high","undergraduate","graduate")
USeducation$education <- factor(USeducation$education, levels = edu_levels)
USeducationT$education <- factor(USeducationT$education, levels = edu_levels)
FigS6USeducation <- ggplot(USeducation, aes(x=education,color=education,fill=education)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=USeducationT, aes(x=education,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Highest education (US)",y="Number of participants") + coord_cartesian(ylim=c(0, 55))

multiplot(FigS6MSgender, FigS6MSage, FigS6MSeducation, FigS6NMSgender, FigS6NMSage, FigS6NMSeducation, FigS6USgender, FigS6USage, FigS6USeducation, cols=3)
```

```{r Fig. S7, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=4.5, fig.align='center',fig.cap="Fig. S7: Overview of participants' profile in Exp2."}
# MS - Place
MSplace <- unique(dataMS[,c("place","workerId")])
place_levels <- c("north","south")
MSplace$place <- factor(MSplace$place, levels = place_levels)
MSplaceT <- as.data.frame(table(MSplace$place));names(MSplaceT) <- c("place","freq")
MSplaceT$place <- factor(MSplaceT$place, levels = place_levels)
FigS7MSplace <- ggplot(MSplace, aes(x=place,color=place,fill=place)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=MSplaceT, aes(x=place,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Place (MS)",y="Number of participants") + coord_cartesian(ylim=c(0, 30))

# NMS - Place
NMSplace <- unique(dataNMS[,c("place","workerId")])
place_levels <- c("north","south")
NMSplace$place <- factor(NMSplace$place, levels = place_levels)
NMSplaceT <- as.data.frame(table(NMSplace$place));names(NMSplaceT) <- c("place","freq")
NMSplaceT$place <- factor(NMSplaceT$place, levels = place_levels)
FigS7NMSplace <- ggplot(NMSplace, aes(x=place,color=place,fill=place)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=NMSplaceT, aes(x=place,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x="Place (NMS)",y="Number of participants") + coord_cartesian(ylim=c(0, 65))

# MS - Exposure to Māori
MSME <- unique(dataMS[,c("maoriExpo","workerId")]);MSME$maoriExpo <- as.factor(MSME$maoriExpo)
MSMET <- as.data.frame(table(MSME$maoriExpo));names(MSMET) <- c("maoriExpo","freq")
FigS7MSME <- ggplot(MSME, aes(x=maoriExpo,color=maoriExpo,fill= maoriExpo)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=MSMET, aes(x=maoriExpo,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x= "Level of exposure (MS)", y = "Number of participants") + coord_cartesian(ylim=c(0, 25))

# NMS - Exposure to Māori
NMSME <- unique(dataNMS[,c("maoriExpo","workerId")]);NMSME$maoriExpo <- as.factor(NMSME$maoriExpo)
NMSMET <- as.data.frame(table(NMSME$maoriExpo));names(NMSMET) <- c("maoriExpo","freq")
FigS7NMSME <- ggplot(NMSME, aes(x=maoriExpo,color=maoriExpo,fill= maoriExpo)) + theme_classic() + geom_bar(aes(),size=.1,show.legend=F) + geom_text(data=NMSMET, aes(x=maoriExpo,y=freq,label=freq), color="black", vjust=-0.2,size=3) + labs(x= "Level of exposure (NMS)", y = "Number of participants") + coord_cartesian(ylim=c(0, 30))

multiplot(FigS7MSplace, FigS7MSME, FigS7NMSplace, FigS7NMSME, cols=2)
```

## Dataset structure

The data is structured as follows:

  - *workerId* is the unique ID for each participant.
  - *enteredResponse* is the wellformedness rating for each stimulus.
  - *reactionTime* is the reaction time for each rating (second).
  - *word* is the stimulus used for the rating.
  - *speakMaori* is each participant's answer to the question how well they can speak Māori (with a scale ranging from 0 to 5).
  - *compMaori* is each participant's answer to the question how well they can understand/read Māori (with a scale ranging from 0 to 5). 
  - *maoriProf* is the sum of quantified response for speakMaori and compMaori, which refers to the level of each participant's Māori proficiency.
  - *age* is the age group where each participant belongs to .
  - *gender* is the gender of each participant. 
  - *ethnicity* is categorized into binary answers, either Māori (M) or non Māori (non M).
  - *education* is each participant's highest level of education.
  - *children* is each participant's answer to the question whether they have had any children who have attended preschool or primary school in New Zealand in the past five years.
  - *maoriList* is each participant's basic knowledge of Māori (with a scale ranging from 0 to 9).
  - *place* is each participant's current place of living (categorized into binary classification, either North or South Island in New Zealand).
  - *duration* is each participant's time duration of living in their current place (categorized into binary classification, long: > 10 years and short: =< 10 years).
  - *firstLang* is each participant's first language.
  - *firstLangCountry* is the country where each participant learned their first language.  
  - *anyOtherLangs* is the information regarding any other languages each participant can speak.
  - *hawaii* is the binary response to the question whether participants have lived in Hawaii.
  - *anyPolynesian* is the binary response to the question whether participants know any Polynesian such as Hawaiian, Tahitian, Sāmoan, or Tongan.
  - *whichPolynesian* is the information regarding participants' knowledge of any Polynesian languages if they knew any.
  - *impairments* is the answer to the question whether participants have a history of any speech or language impairments.
  - *maoriExpo* is each participant's level of exposure to Māori (with a scale ranging from 0 to 10).
  - *group* is the classification of participants according to their fluency of Māori and/or exposure to Māori.
  - *nz* is the binary response to the question whether participants have ever lived in New Zealand.
  - *scoreDictType* is the phonotactic score obtained across word types in the dictionary.
  - *scoreDictToken* is the phonotactic score obtained across tokens of words from the dictionary in running speech corpora. 
  - *scoreRsSegmented* is the phonotactic score obtained across tokens of all words in running speech corpora.
  - *scoreRsUnsegmented* is the phonotactic score obtained across lexically unsegmented stretches of speech in running speech corpora.
  - *scoreDictLongAType* is the phonotactic score obtained across word types in the dictionary ignoring vowel length distinctions except /a~a:/.
  - *scoreDictShortVType* is the phonotactic score obtained across word types in the dictionary ignoring all vowel length distinctions.   
  - *scoreShortVDictNze* is the phonotactic score obtained across words derived from the dictionary of Māori words in New Zealand English.
  - *scoreNBestFixed* is the phonotactic score from 3470 most frequent word types with the lowest AIC score obtained using cutoffs based on raw frequency.
  - *scoreMorphShortVType* is the phonotactic score obtained across morph types derived from words in the dictionary ignoring vowel length distinctions, unweighted. 
  - *scoreMorphShortVToken* is the phonotactic score obtained across tokens of morphs derived from words in the dictionary ignoring vowel length distinctions, based on running speech corpora, weighted by the number of times they occur in corpora.  
  - *median* is the median of each participant's reaction time.

## Number of participants per length within each group
```{r Table S3,echo=FALSE, message=FALSE, warning=FALSE}
dataExp2$word1 <- gsub("\u0101", "A", dataExp2$word, fixed=TRUE)
dataExp2$word1 <- gsub("\u0113", "E", dataExp2$word1, fixed=TRUE)
dataExp2$word1 <- gsub("\u012B", "I", dataExp2$word1, fixed=TRUE)
dataExp2$word1 <- gsub("\u014D", "O", dataExp2$word1, fixed=TRUE)
dataExp2$word1 <- gsub("\u016B", "U", dataExp2$word1, fixed=TRUE)
dataExp2$word1 <- gsub("wh", "f", dataExp2$word1, fixed=TRUE)
dataExp2$word1 <- gsub("ng", "N", dataExp2$word1, fixed=TRUE)
dataExp2$length <- nchar(dataExp2$word1)
dataMS <- dataExp2[dataExp2$group=="MS",]
dataMSlength <- unique(dataMS[,c("length","workerId")])
dataMSlength$length <- as.factor(dataMSlength$length)
dataMSlengthT <- as.data.frame(table(dataMSlength$length))
names(dataMSlengthT) <- c("length", "MS")
dataNMS <- dataExp2[dataExp2$group=="NMS",]
dataNMSlength <- unique(dataNMS[,c("length","workerId")])
dataNMSlength$length <- as.factor(dataNMSlength$length)
dataNMSlengthT <- as.data.frame(table(dataNMSlength$length))
names(dataNMSlengthT) <- c("length", "NMS")
lengthT <- merge(dataMSlengthT, dataNMSlengthT, by="length")
dataUS <- dataExp2[dataExp2$group=="US",]
dataUSlength <- unique(dataUS[,c("length","workerId")])
dataUSlength$length <- as.factor(dataUSlength$length)
dataUSlengthT <- as.data.frame(table(dataUSlength$length))
names(dataUSlengthT) <- c("length", "US")
lengthT <- merge(lengthT, dataUSlengthT, by="length")
kable(lengthT, align="c", caption="Table S3: Number of participants per length within each group")
```

## Comparing AIC scores according to resources
```{r Table S4, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE}
dataExp2$group <- relevel(dataExp2$group, ref="NMS")
dataExp2$enteredResponse <- as.factor(dataExp2$enteredResponse)
dataExp2$macron <- FALSE
dataExp2[grepl("[\\u0101\\u0113\\u012B\\u014D\\u016B]",dataExp2$word),]$macron <- TRUE
dataExp2$macron <- as.factor(dataExp2$macron)

# modelDictType <- clmm(enteredResponse ~ c.(scoreDictType) * group + (1 + c.(scoreDictType) | workerId) + (1 + group | word), dataExp2)
# saveRDS(modelDictType, file = "modelDictType.rds")
modelDictType <- readRDS("./modelDictType.rds")

# modelDictToken <- clmm(enteredResponse ~ c.(scoreDictToken) * group + (1 + c.(scoreDictToken) | workerId) + (1 + group | word), dataExp2)
# saveRDS(modelDictToken, file = "modelDictToken.rds")
modelDictToken <- readRDS("./modelDictToken.rds")

# modelRsSegmented <-  clmm(enteredResponse ~ c.(scoreRsSegmented) * group + (1 + c.(scoreRsSegmented) | workerId) + (1 + group | word), dataExp2)
# saveRDS(modelRsSegmented, file = "modelRsSegmented.rds")
modelRsSegmented <- readRDS("./modelRsSegmented.rds")

# modelRsUnsegmented <-  clmm(enteredResponse ~ c.(scoreRsUnsegmented) * group + (1 + c.(scoreRsUnsegmented) | workerId) + (1 + group | word), dataExp2)
# saveRDS(modelRsUnsegmented, file = "modelRsUnsegmented.rds")
modelRsUnsegmented <- readRDS("./modelRsUnsegmented.rds")

Score <- c("scoreDictType","scoreDictToken","scoreRsSegmented","scoreRsUnsegmented")
AIC <- c(AIC(modelDictType),AIC(modelDictToken),AIC(modelRsSegmented),AIC(modelRsUnsegmented))
aicT <- data.frame(Score,AIC)
kable(aicT, align="c", caption="Table S4: Comparing AIC scores according to resources")
```

## Comparing AIC scores according to vowel length distinction
```{r Table S5, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE}
dataExp2$group <- relevel(dataExp2$group, ref="NMS")
dataExp2$enteredResponse <- as.factor(dataExp2$enteredResponse)
dataExp2$macron <- FALSE
dataExp2[grepl("[\\u0101\\u0113\\u012B\\u014D\\u016B]",dataExp2$word),]$macron <- TRUE
dataExp2$macron <- as.factor(dataExp2$macron)

# modelDictLongAType <- clmm(enteredResponse ~ (c.(scoreDictLongAType) + macron) * group + (1 + c.(scoreDictLongAType) + macron | workerId) + (1 + group | word), data=dataExp2)
# saveRDS(modelDictLongAType, file = "modelDictLongAType.rds")
modelDictLongAType <- readRDS("./modelDictLongAType.rds")

# modelDictShortVType <- clmm(enteredResponse ~ (c.(scoreDictShortVType) + macron) * group + (1 + c.(scoreDictShortVType) + macron | workerId) + (1 + group | word), dataExp2)
# saveRDS(modelDictShortVType, file = "modelDictShortVType.rds")
modelDictShortVType <- readRDS("./modelDictShortVType.rds")

Score <- c("scoreDictType","scoreDictLongAType","scoreDictShortVType")
AIC <- c(AIC(modelDictType),AIC(modelDictLongAType),AIC(modelDictShortVType) )
aicVT <- data.frame(Score,AIC)
kable(aicVT, align="c", caption="Table S5: Comparing AIC scores according to vowel length distinction")
```

##  Well-formedness ratings by participant group (Summary of the best model with the lowest AIC)
```{r Table S6, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE}
kable(clm_table(modelDictShortVType), digits=3, caption="Table S6: Ordinal mixed-effects model summary for well-formedness ratings by participant group. All numeric variables in this model are centered.")
```

## Code for plotting Fig. 2
```{r Fig. 2, echo=FALSE, message=FALSE, warning=FALSE, fig.width=4, fig.height=4, fig.align='center', fig.cap="Fig. 2: Interaction between phonotactic scores and participant groups. The range of phonotactic score is represented on the x-axis and the range of predicted rating is represented on the y-axis."}
thresholds.2a <- data.frame(label=names(modelDictShortVType$alpha), threshold=modelDictShortVType$alpha, row.names=NULL)

fig2a <- as.data.frame(Effect(c("scoreDictShortVType", "group"), mod=modelDictShortVType, latent=TRUE))
names(fig2a)[names(fig2a)=="group"] <- "Group"
fig2a <- add_predicted_ratings(fig2a, thresholds.2a)

ggplot(fig2a, aes(x=scoreDictShortVType, y=predicted.mean, fill=Group, color=Group, shape=Group, linetype=Group)) +
  geom_ribbon(aes(ymin=predicted.lower, ymax=predicted.upper), alpha=0.1, color=NA) + 
  geom_line(size=1) +
  scale_color_manual(values = c("black", "red", "orange")) + 
  scale_fill_manual(values = c("black", "red", "orange")) +
  xlab("Dictionary phonotactic score (Type)") +
  ylab("Predicted Mean Rating") + 
  theme_classic() + 
  theme(legend.position="bottom")
```

### Phonotactics derived from the dictionary of Māori words in New Zealand English
Phonotactics from Māori borrowings in New Zealand English is added as an additional predictor to the best ordinal mixed-effects model presented in Table S6.

```{r AddStats1, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE}
# Phonotactics derived from the dictionary of Māori words in New Zealand English (Macalister, 2005)
# modelMāoriBorrowings <- clmm(enteredResponse ~ ( c.(scoreDictShortVType) + c.(scoreDictNzeShortV) * macron) * group + (1 + c.(scoreDictShortVType) + c.(scoreDictNzeShortV) | workerId) + (0 + macron | workerId) + (1 + group | word), dataExp2)
# saveRDS(modelMāoriBorrowings, file = "modelMāoriBorrowings.rds")
modelMāoriBorrowings <- readRDS("./modelMāoriBorrowings.rds")
kable(clm_table(modelMāoriBorrowings), digits=3, caption="Table S7: Ordinal mixed-effects model of well-formedness ratings including the phonotactics derived from the dictionary of Māori words in New Zealand English")
```

## Post hoc exploration
### Monte Carlo analyses
```{r MC, echo=TRUE, message=FALSE, warning=FALSE, eval=FALSE}
# (1) Monte Carlo analysis with NMS participants for lexicon sizes N ranging from 1k to 18k, drawing 1000 random samples of N types from the lexicon
dir.create("./MC");dir.create("./MC/dictTypeSample");dir.create("./MC/dictTypePM");dir.create("./MC/dictTypePM/aux");dir.create("./MC/dictTypeScore");dir.create("./MC/dictTypeResult")
for(i in 1:18){
  directoryName <- paste0("./MC/dictTypeSample/size",i,"k");dir.create(directoryName)
}
for(i in 1:18){
  directoryName <- paste0("./MC/dictTypePM/size",i,"k");dir.create(directoryName)
}
for(i in 1:18){
  directoryName <- paste0("./MC/dictTypePM/aux/size",i,"k");dir.create(directoryName)
}
for(i in 1:18){
  directoryName <- paste0("./MC/dictTypeScore/size",i,"k");dir.create(directoryName)
}
dictShortVType <- read.delim("./dict-shortvowels_types.txt", sep="\t", header= FALSE)
for(i in 1:18){
wdSample <- paste0("./MC/dictTypeSample/size",i,"k");m <- i*1000;set.seed(1234);setwd(wdSample)
for(j in 1:1000){
randomWords <- sample(dictShortVType$V1, m, replace = FALSE);outputFile <- paste0("randomization_", j, ".txt")
write.table(randomWords, outputFile, row.names = FALSE, col.names=FALSE, quote=FALSE)
# Generate phonotactic scores for each sample using "score-nofreq.sh"
shellCommand <- paste0("./score-nofreq.sh ./MC/dictTypeSample/size",i,"k/randomization_",j,".txt ./stimuli-shortvowels.txt ./MC/dictTypePM/size",i,"k ./MC/dictTypePM/aux/size",i,"k ./MC/dictTypeScore/size",i,"k")
system(shellCommand, intern = TRUE)
}
setwd("./../../..");wdScore <- paste0("./MC/dictTypeScore/size",i,"k");setwd(wdScore)
dataNMS <- dataExp2[dataExp2$group=="NMS",]
dataNMS <- dataNMS[c("enteredResponse","word","word1","length","macron","scoreDictShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataNMS$item <- dataNMS$word1;dataNew <- merge(dataNMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
# Run ordinal regression models with 1000 samples
for(k in 1:1000){
  files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
  clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
  listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
}
setwd("./../../..");wdResult <- paste0("./MC/dictTypeResult");setwd(wdResult);outputAIC <- paste0("dictTypeSize",i,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

# (2) Repeating the same Monte Carlo analysis with MS participants for lexicon sizes N ranging from 1k to 18k, drawing 1000 random samples of N types from the lexicon
dir.create("./MC/msDictTypeResult")
for(i in 1:18){
wdScore <- paste0("./MC/dictTypeScore/size",i,"k");setwd(wdScore)
dataMS <- dataExp2[dataExp2$group=="MS",]
dataMS <- dataMS[c("enteredResponse","word","word1","length","macron","scoreDictShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataMS$item <- dataMS$word1;dataNew <- merge(dataMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:1000){
  files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
  clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
  listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
}
setwd("./../../..");wdResult <- paste0("./MC/msDictTypeResult");setwd(wdResult);outputAIC <- paste0("msDictTypeSize",i,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC, row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

# (3) Monte Carlo analysis with NMS participants for lexicon sizes N ranging from 1k to 18k, drawing 1000 random samples of N types from the lexicon, weighted by token frequency
dir.create("./MC/dictTokenSample");dir.create("./MC/dictTokenPM");dir.create("./MC/dictTokenPM/aux");dir.create("./MC/dictTokenScore");dir.create("./MC/dictTokenResult")
for(i in 1:18){
  directoryName <- paste0("./MC/dictTokenSample/size",i,"k");dir.create(directoryName)
}
for(i in 1:18){
  directoryName <- paste0("./MC/dictTokenPM/size",i,"k");dir.create(directoryName)
}
for(i in 1:18){
  directoryName <- paste0("./MC/dictTokenPM/aux/size",i,"k");dir.create(directoryName)
}
for(i in 1:18){
  directoryName <- paste0("./MC/dictTokenScore/size",i,"k");dir.create(directoryName)
}
dictShortVFreq <- read.delim("./dict-shortvowels_freq.txt", sep="\t", header= TRUE)
for(i in 1:18){
wdSample <- paste0("./MC/dictTokenSample/size",i,"k");m <- i*1000;set.seed(1234);setwd(wdSample)
for(j in 1:1000){randomWords <- sample(dictShortVFreq$word, m, replace = FALSE, prob = dictShortVFreq$tokens);randomWords <- gsub(""," ",randomWords);randomWords <- gsub("^ ","",randomWords);randomWords <- gsub(" $","",randomWords);outputFile <- paste0("randomization_", j, ".txt")
write.table(randomWords, outputFile, row.names = FALSE, col.names=FALSE, quote=FALSE)
shellCommand <- paste0("./score-nofreq.sh ./MC/dictTokenSample/size",i,"k/randomization_",j,".txt ./stimuli-shortvowels.txt ./MC/dictTokenPM/size",i,"k ./MC/dictTokenPM/aux/size",i,"k ./MC/dictTokenScore/size",i,"k")
system(shellCommand, intern = TRUE)
}
setwd("./../../..");wdScore <- paste0("./MC/dictTokenScore/size",i,"k");setwd(wdScore)
dataNMS <- dataExp2[dataExp2$group=="NMS",]
dataNMS <- dataNMS[c("enteredResponse","word","word1","length","macron","scoreDictShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataNMS$item <- dataNMS$word1;dataNew <- merge(dataNMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:1000){
  files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
  clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
  listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
}
setwd("./../../..");wdResult <- paste0("./MC/dictTokenResult");setwd(wdResult);outputAIC <- paste0("dictTokenSize",i,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

# (4) Repeating the same Monte Carlo analysis with MS participants for lexicon sizes N ranging from 1k to 18k, drawing 1000 random samples of N types from the lexicon, weighted by token frequency
dir.create("./MC/msDictTokenResult")
for(i in 1:18){
wdScore <- paste0("./MC/dictTokenScore/size",i,"k");setwd(wdScore)
dataMS <- dataExp2[dataExp2$group=="MS",]
dataMS <- dataMS[c("enteredResponse","word","word1","length","macron","scoreDictShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataMS$item <- dataMS$word1;dataNew <- merge(dataMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:1000){
  files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
  clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
  listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
}
setwd("./../../..");wdResult <- paste0("./MC/msDictTokenResult");setwd(wdResult);outputAIC <- paste0("msDictTokenSize",i,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC, row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

# (5) Monte Carlo analysis with NMS participants for lexicon sizes N ranging from 1k to 18k, consisting of the randomly sampled N highest-frequency types in the lexicon 
dir.create("./MC/NBestSample");dir.create("./MC/NBestPM");dir.create("./MC/NBestPM/aux");dir.create("./MC/NBestScore");dir.create("./MC/NBestResult")
for(i in 1:18){
  directoryName <- paste0("./MC/NBestSample/size",i,"k");dir.create(directoryName)
}
for(i in 1:18){
  directoryName <- paste0("./MC/NBestPM/size",i,"k");dir.create(directoryName)
}
for(i in 1:18){
  directoryName <- paste0("./MC/NBestPM/aux/size",i,"k");dir.create(directoryName)
}
for(i in 1:18){
  directoryName <- paste0("./MC/NBestScore/size",i,"k");dir.create(directoryName)
}
dictShortVFreq <- read.delim("./dict-shortvowels_freq.txt", sep="\t", header= TRUE)
for(i in 1:18){
wdSample <- paste0("./MC/NBestSample/size",i,"k");m <- i*1000;setwd(wdSample)
for(j in 1:1000){
dictShortVFreq <- dictShortVFreq[order(runif(nrow(dictShortVFreq))),]
dictShortVFreq <- dictShortVFreq[order(dictShortVFreq$tokens, decreasing=TRUE),]  
randomWords <- dictShortVFreq$word[1:m]
randomWords <- gsub(""," ",randomWords);randomWords <- gsub("^ ","",randomWords);randomWords <- gsub(" $","",randomWords);outputFile <- paste0("randomization_", j, ".txt")
write.table(randomWords, outputFile, row.names = FALSE, col.names=FALSE, quote=FALSE)
shellCommand <- paste0("./score-nofreq.sh ./MC/NBestSample/size",i,"k/randomization_",j,".txt ./stimuli-shortvowels.txt ./MC/NBestPM/size",i,"k ./MC/NBestPM/aux/size",i,"k /MC/NBestScore/size",i,"k")
system(shellCommand, intern = TRUE)
}
setwd("./../../..");wdScore <- paste0("./MC/NBestScore/size",i,"k");setwd(wdScore)
dataNMS <- dataExp2[dataExp2$group=="NMS",]
dataNMS <- dataNMS[c("enteredResponse","word","word1","length","macron","scoreDictShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataNMS$item <- dataNMS$word1;dataNew <- merge(dataNMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:1000){
  files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
  clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
  listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
}
setwd("./../../..");wdResult <- paste0("./MC/NBestResult");setwd(wdResult);outputAIC <- paste0("NBestSize",i,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

# (6) Repeating the same Monte Carlo analysis with MS participants for lexicon sizes N ranging from 1k to 18k, consisting of the randomly sampled N highest-frequency types in the lexicon
dir.create("./MC/msNBestResult")
for(i in 1:18){
wdScore <- paste0("./MC/NBestScore/size",i,"k");setwd(wdScore)
dataMS <- dataExp2[dataExp2$group=="MS",]
dataMS <- dataMS[c("enteredResponse","word","word1","length","macron","scoreDictShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataMS$item <- dataMS$word1;dataNew <- merge(dataMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:1000){
  files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
  clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
  listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
}
setwd("./../../..");wdResult <- paste0("./MC/msNBestResult");setwd(wdResult);outputAIC <- paste0("msNBestSize",i,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC, row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

# (7) Monte Carlo analysis with NMS participants for lexicon sizes N ranging from 3k to 18k (using cutoffs based on raw frequency), consisting of the fixed N-most-frequent types appearing at least five times in running speech
dir.create("./MC/NBestFixedSample");dir.create("./MC/NBestFixedPM");dir.create("./MC/NBestFixedPM/aux");dir.create("./MC/NBestFixedScore");dir.create("./MC/NBestFixedResult")
dictShortVFreqCutOffs <- read.delim("./dict-shortvowels_freq_cutoffs.txt", sep="\t", header= TRUE)
listCutOffs <- dictShortVFreqCutOffs[dictShortVFreqCutOffs$N > 3000,]$N
for(i in listCutOffs){
wdSample <- paste0("./MC/NBestFixedSample");setwd(wdSample)
dictShortVFreq <- dictShortVFreq[order(dictShortVFreq$tokens.raw, decreasing=TRUE),]
randomWords <- dictShortVFreq$word[1:i];randomWords <- gsub(""," ",randomWords);randomWords <- gsub("^ ","",randomWords);randomWords <- gsub(" $","",randomWords)
outputFile <- paste0("NBestFixedSample",i,".txt")
write.table(randomWords, outputFile, row.names = FALSE, col.names=FALSE, quote=FALSE)
shellCommand <- paste0("./score-nofreq.sh ./MC/NBestFixedSample/NBestFixedSample",i,".txt ./stimuli-shortvowels.txt ./MC/NBestFixedPM ./MC/NBestFixedPM/aux ./MC/NBestFixedScore")
system(shellCommand, intern = TRUE)
setwd("./../..")
}
dataNMS <- dataExp2[dataExp2$group=="NMS",]
dataNMS <- dataNMS[c("enteredResponse","word","word1","length","macron","scoreDictShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataNMS$item <- dataNMS$word1;dataNew <- merge(dataNMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
wdScore <- paste0("./MC/NBestFixedScore");setwd(wdScore)
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:6){
  files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
  clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
  listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
}
setwd("./../..");wdResult <- paste0("./MC/NBestFixedResult");setwd(wdResult);outputAIC <- paste0("NBestFixedListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")

listAIC <- as.data.frame(unlist(listAIC));list <- data.frame(cbind(unlist(listCutOffs)))
listAIC <- cbind(listAIC, list);colnames(listAIC) <- c("AICscore","size")
listAIC$size[(which(listAIC==min(listAIC$AICscore)))] # 3470
min(listAIC$AICscore) # 103767.4
listAIC <- listAIC[,c("size", "AICscore")];colnames(listAIC) <- c("Cutoff","AIC")
# write.table(listAIC,"dataTableS7.txt",sep ="\t", quote=FALSE, row.names=FALSE, col.names=TRUE)

# (8) Repeating the same Monte Carlo analysis with MS participants for lexicon sizes N ranging from 3k to 18k (using cutoffs based on raw frequency), consisting of the fixed N-most-frequent types appearing at least five times in running speech
dir.create("./MC/msNBestFixedResult")
dataMS <- dataExp2[dataExp2$group=="MS",]
dataMS <- dataMS[c("enteredResponse","word","word1","length","macron","scoreDictShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataMS$item <- dataMS$word1;dataNew <- merge(dataMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
wdScore <- paste0("./MC/NBestFixedScore");setwd(wdScore)
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:6){
  files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
  clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
  listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
}
setwd("./../..");wdResult <- paste0("./MC/msNBestFixedResult");setwd(wdResult);outputAIC <- paste0("msNBestFixedListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")

listAIC <- as.data.frame(unlist(listAIC));list <- data.frame(cbind(unlist(listCutOffs)))
listAIC <- cbind(listAIC, list);colnames(listAIC) <- c("AICscore","size")
listAIC$size[(which(listAIC==min(listAIC$AICscore)))] # 3879
min(listAIC$AICscore) # 36657.44
listAIC <- listAIC[,c("size", "AICscore")];colnames(listAIC) <- c("Cutoff","AIC")
# write.table(listAIC,"dataTableS8.txt",sep ="\t", quote=FALSE, row.names=FALSE, col.names=TRUE)

for(i in 1:18){
  assign(paste0("size",i,"k"),read.delim(paste0("./MC/dictTypeResult/dictTypeSize",i,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size1k$size <- "1k";size2k$size <- "2k";size3k$size <- "3k";size4k$size <- "4k";size5k$size <- "5k";size6k$size <- "6k";size7k$size <- "7k";size8k$size <- "8k";size9k$size <- "9k";size10k$size <- "10k";size11k$size <- "11k";size12k$size <- "12k";size13k$size <- "13k";size14k$size <- "14k";size15k$size <- "15k";size16k$size <- "16k";size17k$size <- "17k";size18k$size <- "18k"
dictTypeAIC <- rbind(size1k, size2k, size3k, size4k, size5k, size6k, size7k, size8k, size9k, size10k, size11k, size12k, size13k, size14k, size15k, size16k, size17k, size18k)
dictTypeAIC$type <- "unweighted"

for(i in 1:18){
  assign(paste0("size",i,"k"),read.delim(paste0("./MC/dictTokenResult/dictTokenSize",i,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size1k$size <- "1k";size2k$size <- "2k";size3k$size <- "3k";size4k$size <- "4k";size5k$size <- "5k";size6k$size <- "6k";size7k$size <- "7k";size8k$size <- "8k";size9k$size <- "9k";size10k$size <- "10k";size11k$size <- "11k";size12k$size <- "12k";size13k$size <- "13k";size14k$size <- "14k";size15k$size <- "15k";size16k$size <- "16k";size17k$size <- "17k";size18k$size <- "18k"
dictTokenAIC <- rbind(size1k, size2k, size3k, size4k, size5k, size6k, size7k, size8k, size9k, size10k, size11k, size12k, size13k, size14k, size15k, size16k, size17k, size18k)
dictTokenAIC$type <- "frequency-weighted"

for(i in 1:18){
  assign(paste0("size",i,"k"),read.delim(paste0("./MC/NBestResult/NBestSize",i,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size1k$size <- "1k";size2k$size <- "2k";size3k$size <- "3k";size4k$size <- "4k";size5k$size <- "5k";size6k$size <- "6k";size7k$size <- "7k";size8k$size <- "8k";size9k$size <- "9k";size10k$size <- "10k";size11k$size <- "11k";size12k$size <- "12k";size13k$size <- "13k";size14k$size <- "14k";size15k$size <- "15k";size16k$size <- "16k";size17k$size <- "17k";size18k$size <- "18k"
NBestAIC <- rbind(size1k, size2k, size3k, size4k, size5k, size6k, size7k, size8k, size9k, size10k, size11k, size12k, size13k, size14k, size15k, size16k, size17k, size18k)
NBestAIC$type <- "N highest-frequency" 

nmsAIC <- rbind(dictTypeAIC, dictTokenAIC, NBestAIC)

for(i in 1:18){
  assign(paste0("size",i,"k"),read.delim(paste0("./MC/msDictTypeResult/msDictTypeSize",i,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size1k$size <- "1k";size2k$size <- "2k";size3k$size <- "3k";size4k$size <- "4k";size5k$size <- "5k";size6k$size <- "6k";size7k$size <- "7k";size8k$size <- "8k";size9k$size <- "9k";size10k$size <- "10k";size11k$size <- "11k";size12k$size <- "12k";size13k$size <- "13k";size14k$size <- "14k";size15k$size <- "15k";size16k$size <- "16k";size17k$size <- "17k";size18k$size <- "18k"
msDictTypeAIC <- rbind(size1k, size2k, size3k, size4k, size5k, size6k, size7k, size8k, size9k, size10k, size11k, size12k, size13k, size14k, size15k, size16k, size17k, size18k)
msDictTypeAIC$type <- "unweighted"

for(i in 1:18){
  assign(paste0("size",i,"k"),read.delim(paste0("./MC/msDictTokenResult/msDictTokenSize",i,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size1k$size <- "1k";size2k$size <- "2k";size3k$size <- "3k";size4k$size <- "4k";size5k$size <- "5k";size6k$size <- "6k";size7k$size <- "7k";size8k$size <- "8k";size9k$size <- "9k";size10k$size <- "10k";size11k$size <- "11k";size12k$size <- "12k";size13k$size <- "13k";size14k$size <- "14k";size15k$size <- "15k";size16k$size <- "16k";size17k$size <- "17k";size18k$size <- "18k"
msDictTokenAIC <- rbind(size1k, size2k, size3k, size4k, size5k, size6k, size7k, size8k, size9k, size10k, size11k, size12k, size13k, size14k, size15k, size16k, size17k, size18k)
msDictTokenAIC$type <- "frequency-weighted"

for(i in 1:18){
  assign(paste0("size",i,"k"),read.delim(paste0("./MC/msNBestResult/msNBestSize",i,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size1k$size <- "1k";size2k$size <- "2k";size3k$size <- "3k";size4k$size <- "4k";size5k$size <- "5k";size6k$size <- "6k";size7k$size <- "7k";size8k$size <- "8k";size9k$size <- "9k";size10k$size <- "10k";size11k$size <- "11k";size12k$size <- "12k";size13k$size <- "13k";size14k$size <- "14k";size15k$size <- "15k";size16k$size <- "16k";size17k$size <- "17k";size18k$size <- "18k"
msNBestAIC <- rbind(size1k, size2k, size3k, size4k, size5k, size6k, size7k, size8k, size9k, size10k, size11k, size12k, size13k, size14k, size15k, size16k, size17k, size18k)
msNBestAIC$type <- "N highest-frequency"

msAIC <- rbind(msDictTypeAIC, msDictTokenAIC, msNBestAIC)
# write.table(nmsAIC,"dataFig3NMS.txt",sep ="\t", quote=FALSE, row.names=FALSE, col.names=TRUE)
# write.table(msAIC,"dataFig3MS.txt",sep ="\t", quote=FALSE, row.names=FALSE, col.names=TRUE)

# Run ordinal regression models with full lexicon
clmfitFullDictNMS <- clm(enteredResponse ~ scoreDictShortVType + macron, data=dataNMS)
clmfitFullDictMS <- clm(enteredResponse ~ scoreDictShortVType + macron, data=dataMS)
# saveRDS(clmfitFullDictNMS, file = "fullDictNMS.rds")
# saveRDS(clmfitFullDictMS, file = "fullDictMS.rds")
```

### Comparing AIC scores using cutoffs based on raw frequency
```{r Table S7-8, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE}
TableS7 <- read.delim("./dataTableS7.txt", sep ="\t", header = TRUE)
kable(TableS7, align="c", caption="Table S8: Comparing AIC scores with NMS participants, using cutoffs based on raw frequency")

TableS8 <- read.delim("./dataTableS8.txt", sep ="\t", header = TRUE)
kable(TableS8, align="c", caption="Table S9: Comparing AIC scores with MS participants, using cutoffs based on raw frequency")
```

### Code for plotting Fig. 3
```{r Fig. 3, echo=FALSE, message=FALSE, warning=FALSE, fig.width=11, fig.height=7.5, fig.cap="Fig. 3: Monte Carlo simulations with 1,000 random samples over 18 dictionary sizes. The bars represent bootstrap 95% confidence intervals."}
fig3NMS <- read.delim("./dataFig3NMS.txt", sep ="\t", header = TRUE)
fig3NMS$size <- ordered(fig3NMS$size, levels = c("1k","2k","3k","4k","5k","6k","7k","8k","9k","10k","11k","12k","13k","14k","15k","16k","17k","18k"))
fullDictNMS <- readRDS("./fullDictNMS.rds");fullDictAICNMS <- AIC(fullDictNMS)
levels(fig3NMS$type) <- c("frequency-weighted", "N highest-frequency", "unweighted")

fig3NMS.summary <- fig3NMS %>%
  group_by(size, type) %>%
  summarise(
    mean.AIC = mean(V1),
    lower.AIC = quantile(V1, probs=c(0.025)),
    upper.AIC = quantile(V1, probs=c(0.975))
  )

fig3A <- ggplot(fig3NMS.summary, aes(x=as.numeric(size), y=mean.AIC, ymin=lower.AIC, ymax=upper.AIC)) +
  geom_errorbar(aes(color=type), position=position_dodge(width=0.2), size=1) +
  geom_line(aes(color=type), position=position_dodge(width=0.2), size=1, alpha=0.5) +
  geom_hline(aes(yintercept=fullDictAICNMS, linetype="Full dictionary (18k)"), color="black", size=1) +   
  geom_point(aes(fill=type), shape=21, position=position_dodge(width=0.2), size=3) +
  labs(title="Monte carlo simulations with NMS participants",x="Lexicon size", y="AIC score") + 
  theme_classic() + 
  scale_linetype_manual(values=c("Full dictionary (18k)"="dashed")) +  
  scale_x_continuous(breaks=1:18, labels=levels(fig3NMS.summary$size)) +
  theme(
    plot.title=element_text(hjust=0.5, size=15),
    legend.text=element_text(size=10),
    legend.title = element_blank())

fig3MS <- read.delim("./dataFig3MS.txt", sep ="\t", header = TRUE)
fig3MS$size <- ordered(fig3MS$size, levels = c("1k","2k","3k","4k","5k","6k","7k","8k","9k","10k","11k","12k","13k","14k","15k","16k","17k","18k"))
fullDictMS <- readRDS("./fullDictMS.rds");fullDictAICMS <- AIC(fullDictMS)
levels(fig3MS$type) <- c("frequency-weighted", "N highest-frequency", "unweighted")

fig3MS.summary <- fig3MS %>%
  group_by(size, type) %>%
  summarise(
    mean.AIC = mean(V1),
    lower.AIC = quantile(V1, probs=c(0.025)),
    upper.AIC = quantile(V1, probs=c(0.975))
  )

fig3B <- ggplot(fig3MS.summary, aes(x=as.numeric(size), y=mean.AIC, ymin=lower.AIC, ymax=upper.AIC)) +
  geom_errorbar(aes(color=type), position=position_dodge(width=0.2), size=1) +
  geom_line(aes(color=type), position=position_dodge(width=0.2), size=1, alpha=0.5) +
  geom_hline(aes(yintercept=fullDictAICMS, linetype="Full dictionary (18k)"), color="black", size=1) +   
  geom_point(aes(fill=type), shape=21, position=position_dodge(width=0.2), size=3) +
  labs(title="Monte carlo simulations with MS participants",x="Lexicon size", y="AIC score") + 
  theme_classic() + 
  scale_linetype_manual(values=c("Full dictionary (18k)"="dashed")) +  
  scale_x_continuous(breaks=1:18, labels=levels(fig3MS.summary$size)) +
  theme(
    plot.title=element_text(hjust=0.5, size=15),
    legend.text=element_text(size=10),
    legend.title = element_blank())

multiplot(fig3A,fig3B, cols=1)
```

## Comparing AIC scores for model selection for sub-word units (morphs)
```{r Morph, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE}
# modelMorphShortVType <- clmm(enteredResponse ~ (c.(scoreMorphShortVType) + macron) * group + (1 + c.(scoreMorphShortVType) + macron | workerId) + (1 + group | word), dataExp2)
# saveRDS(modelMorphShortVType, file = "modelMorphShortVType.rds")
modelMorphShortVType <- readRDS("./modelMorphShortVType.rds")

# modelMorphShortVToken <- clmm(enteredResponse ~ (c.(scoreMorphShortVToken) + macron) * group + (1 + c.(scoreMorphShortVToken) + macron | workerId) + (1 + group | word), dataExp2)
# saveRDS(modelMorphShortVToken, file = "modelMorphShortVToken.rds")
modelMorphShortVToken <- readRDS("./modelMorphShortVToken.rds")
modelNBestFixedNMS <- readRDS("./modelBestFixedNMS.rds")

Score <- c("scoreDictShortVType","scoreMorphShortVType","scoreMorphShortVToken")
AIC <- c(AIC(modelDictShortVType),AIC(modelMorphShortVType),AIC(modelMorphShortVToken))
aicMorphT <- data.frame(Score,AIC)
kable(aicMorphT, align="c", caption="Table S10: Comparing AIC score for model selection for sub-word units (morphs)")
```

## Phonotactic knowledge from morphs (Summary of the best model with the lowest AIC)
```{r Table S11, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE}
kable(clm_table(modelMorphShortVType), digits=3, caption="Table S11: Ordinal mixed-effects model summary for well-formedness ratings by participant group for sub-word units (morphs). All numeric variables in this model are centered.")
```

### Monte Carlo analyses with the phonotactics derived from morphs
```{r MC_morphs, echo=TRUE, message=FALSE, warning=FALSE, eval=FALSE}
# (1) Monte Carlo analysis with NMS participants for morph set sizes N ranging from 0.5k to 3.5k, drawing 1000 random samples of N types from the morph set
dir.create("./MC/morphTypeSample");dir.create("./MC/morphTypePM");dir.create("./MC/morphTypePM/aux");dir.create("./MC/morphTypeScore");dir.create("./MC/morphTypeResult")
for(i in 1:7){
  directoryName <- paste0("./MC/morphTypeSample/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphTypePM/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphTypePM/aux/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphTypeScore/size",i*0.5,"k");dir.create(directoryName)
}
morphShortVFreq <- read.delim("./morphs-shortvowels_freq.txt", sep="\t", header= TRUE)
for(i in 1:7){
wdSample <- paste0("./MC/morphTypeSample/size",i*0.5,"k");m <- i*500;set.seed(1234);setwd(wdSample)
for(j in 1:1000){
randomMorphs <- sample(morphShortVFreq$morph, m, replace = FALSE)
randomMorphs <- gsub(""," ",randomMorphs);randomMorphs <- gsub("^ ","",randomMorphs);randomMorphs <- gsub(" $","",randomMorphs);outputFile <- paste0("randomization_", j, ".txt")
write.table(randomMorphs, outputFile, row.names = FALSE, col.names=FALSE, quote=FALSE)
shellCommand <- paste0("./score-nofreq_morphs.sh ./MC/morphTypeSample/size",i*0.5,"k/randomization_",j,".txt ./stimuli-shortvowels_morphs.txt ./MC/morphTypePM/size",i*0.5,"k ./MC/morphTypePM/aux/size",i*0.5,"k ./MC/morphTypeScore/size",i*0.5,"k")
system(shellCommand, intern = TRUE)
}
setwd("./../../..");wdScore <- paste0("./MC/morphTypeScore/size",i*0.5,"k");setwd(wdScore)
dataNMS <- dataExp2[dataExp2$group=="NMS",]
dataNMS <- dataNMS[c("enteredResponse","word","word1","length","macron","scoreMorphShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataNMS$item <- dataNMS$word1;dataNew <- merge(dataNMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:1000){
    files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
    clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
    listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
  }
setwd("./../../..");wdResult <- paste0("./MC/morphTypeResult");setwd(wdResult)
outputAIC <- paste0("morphTypeSize",i*0.5,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

# (2) Repeating the same Monte Carlo analysis with MS participants for morph set sizes N ranging from 0.5k to 3.5k, drawing 1000 random samples of N types from the morph set
dir.create("./MC/msMorphTypeResult")
for(i in 1:7){
wdScore <- paste0("./MC/morphTypeScore/size",i*0.5,"k");setwd(wdScore)
dataMS <- dataExp2[dataExp2$group=="MS",]
dataMS <- dataMS[c("enteredResponse","word","word1","length","macron","scoreMorphShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataMS$item <- dataMS$word1;dataNew <- merge(dataMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:1000){
    files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
    clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
    listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
  }
setwd("./../../..");wdResult <- paste0("./MC/msMorphTypeResult");setwd(wdResult)
outputAIC <- paste0("msMorphTypeSize",i*0.5,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

# (3) Monte Carlo analysis with NMS participants for morph set sizes N ranging from 0.5k to 3.5k, drawing 1000 random samples of N types from the morph set, weighted by their token frequency in running speech 
dir.create("./MC/morphTokenSample");dir.create("./MC/morphTokenPM");dir.create("./MC/morphTokenPM/aux");dir.create("./MC/morphTokenScore");dir.create("./MC/morphTokenResult")
for(i in 1:7){
  directoryName <- paste0("./MC/morphTokenSample/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphTokenPM/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphTokenPM/aux/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphTokenScore/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
wdSample <- paste0("./MC/morphTokenSample/size",i*0.5,"k");m <- i*500;set.seed(1234);setwd(wdSample)
for(j in 1:1000){randomMorphs <- sample(morphShortVFreq$morph, m, replace = FALSE, prob=morphShortVFreq$tokens)
randomMorphs <- gsub(""," ",randomMorphs);randomMorphs <- gsub("^ ","",randomMorphs);randomMorphs <- gsub(" $","",randomMorphs);outputFile <- paste0("randomization_", j, ".txt")  
write.table(randomMorphs, outputFile, row.names = FALSE, col.names=FALSE, quote=FALSE)
shellCommand <- paste0("./score-nofreq_morphs.sh ./MC/morphTokenSample/size",i*0.5,"k/randomization_",j,".txt ./stimuli-shortvowels_morphs.txt ./MC/morphTokenPM/size",i*0.5,"k ./MC/morphTokenPM/aux/size",i*0.5,"k ./MC/morphTokenScore/size",i*0.5,"k")
system(shellCommand, intern = TRUE)
} 
setwd("./../../..");wdScore <- paste0("./MC/morphTokenScore/size",i*0.5,"k");setwd(wdScore)
dataNMS <- dataExp2[dataExp2$group=="NMS",]
dataNMS <- dataNMS[c("enteredResponse","word","word1","macron","scoreMorphShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list); list <- list[,c("item","logprob")]
  dataNMS$item <- dataNMS$word1;dataNew <- merge(dataNMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
  }  
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:1000){
    files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
    clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
    listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
  }
setwd("./../../..");wdResult <- paste0("./MC/morphTokenResult");setwd(wdResult)
outputAIC <- paste0("morphTokenSize",i*0.5,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

# (4) Repeating the same Monte Carlo analysis with MS participants for morph set sizes N ranging from 0.5k to 3.5k, drawing 1000 random samples of N types from the morph set, weighted by their token frequency in running speech 
dir.create("./MC/msMorphTokenResult")
for(i in 1:7){
wdScore <- paste0("./MC/morphTokenScore/size",i*0.5,"k");setwd(wdScore)
dataMS <- dataExp2[dataExp2$group=="MS",]
dataMS <- dataMS[c("enteredResponse","word","word1","length","macron","scoreMorphShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataMS$item <- dataMS$word1;dataNew <- merge(dataMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:1000){
    files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
    clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
    listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
  }
setwd("./../../..");wdResult <- paste0("./MC/msMorphTokenResult");setwd(wdResult)
outputAIC <- paste0("msMorphTokenSize",i*0.5,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

# (5) Monte Carlo analysis with NMS participants for morph set sizes N ranging from 0.5k to 3.5k, drawing 1000 random samples of N-best morph types from the morph set, weighted by their token frequency in running speech
dir.create("./MC/morphTokenNBestSample");dir.create("./MC/morphTokenNBestPM");dir.create("./MC/morphTokenNBestPM/aux");dir.create("./MC/morphTokenNBestScore");dir.create("./MC/morphTokenNBestResult")
for(i in 1:7){
  directoryName <- paste0("./MC/morphTokenNBestSample/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphTokenNBestPM/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphTokenNBestPM/aux/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphTokenNBestScore/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
wdSample <- paste0("./MC/morphTokenNBestSample/size",i*0.5,"k");m <- i*500;setwd(wdSample)
for(j in 1:1000){
morphShortVFreq <- morphShortVFreq[order(runif(nrow(morphShortVFreq))),]
morphShortVFreq <- morphShortVFreq[order(morphShortVFreq$tokens.raw, decreasing=TRUE),]
randomMorphs <- morphShortVFreq$morph[1:m]  
randomMorphs <- gsub(""," ",randomMorphs);randomMorphs <- gsub("^ ","",randomMorphs);randomMorphs <- gsub(" $","",randomMorphs);outputFile <- paste0("randomization_", j, ".txt")
write.table(randomMorphs, outputFile, row.names = FALSE, col.names=FALSE, quote=FALSE)
shellCommand <- paste0("./score-nofreq_morphs.sh ./MC/morphTokenNBestSample/size",i*0.5,"k/randomization_",j,".txt ./stimuli-shortvowels_morphs.txt ./MC/morphTokenNBestPM/size",i*0.5,"k ./MC/morphTokenNBestPM/aux/size",i*0.5,"k ./MC/morphTokenNBestScore/size",i*0.5,"k")
system(shellCommand, intern = TRUE)
}
setwd("./../../..");wdScore <- paste0("./MC/morphTokenNBestScore/size",i*0.5,"k");setwd(wdScore)
dataNMS <- dataExp2[dataExp2$group=="NMS",]
dataNMS <- dataNMS[c("enteredResponse","word","word1","macron","scoreMorphShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataNMS$item <- dataNMS$word1;dataNew <- merge(dataNMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
  }
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:1000){
    files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
    clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
    listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
  }
setwd("./../../..");wdResult <- paste0("./MC/morphTokenNBestResult");setwd(wdResult)
outputAIC <- paste0("morphTokenNBestSize",i*0.5,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

# (6) Repeating the same Monte Carlo analysis with MS participants for morph set sizes N ranging from 0.5k to 3.5k, drawing 1000 random samples of N-best morph types from the morph set, weighted by their token frequency in running speech
dir.create("./MC/msMorphTokenNBestResult")
for(i in 1:7){
wdScore <- paste0("./MC/morphTokenNBestScore/size",i*0.5,"k");setwd(wdScore)
dataMS <- dataExp2[dataExp2$group=="MS",]
dataMS <- dataMS[c("enteredResponse","word","word1","length","macron","scoreMorphShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataMS$item <- dataMS$word1;dataNew <- merge(dataMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:1000){
    files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
    clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
    listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
  }
setwd("./../../..");wdResult <- paste0("./MC/msMorphTokenNBestResult");setwd(wdResult)
outputAIC <- paste0("msMorphTokenNBestSize",i*0.5,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

# (7) Monte Carlo analysis with NMS participants for morph set sizes N ranging from 0.5k to 3.5k (using cutoffs based on raw frequency of the words they appear in), consisting of the fixed N-best morph types appearing at least 15 times in running speech
dir.create("./MC/morphNBestFixedSample");dir.create("./MC/morphNBestFixedPM");dir.create("./MC/morphNBestFixedPM/aux");dir.create("./MC/morphNBestFixedScore");dir.create("./MC/morphNBestFixedResult")
morphShortVFreqCutOffs <- read.delim("./morphs-shortvowels_freq_cutoffs.txt", sep="\t", header= TRUE)
listCutOffs <- morphShortVFreqCutOffs[morphShortVFreqCutOffs$N > 1000,]$N
for(i in listCutOffs){
wdSample <- paste0("./MC/morphNBestFixedSample");setwd(wdSample)
morphShortVFreq <- morphShortVFreq[order(morphShortVFreq$tokens.raw, decreasing=TRUE),]
randomMorphs <- morphShortVFreq$morph[1:i];randomMorphs <- gsub(""," ",randomMorphs);randomMorphs <- gsub("^ ","",randomMorphs);randomMorphs <- gsub(" $","",randomMorphs)
outputFile <- paste0("morphNBestFixedSample",i,".txt")
write.table(randomMorphs, outputFile, row.names = FALSE, col.names=FALSE, quote=FALSE)
shellCommand <- paste0("./score-nofreq_morphs.sh ./MC/morphNBestFixedSample/morphNBestFixedSample",i,".txt ./stimuli-shortvowels_morphs.txt ./MC/morphNBestFixedPM ./MC/morphNBestFixedPM/aux ./MC/morphNBestFixedScore")
system(shellCommand, intern = TRUE)
setwd("./../..")
}
dataNMS <- dataExp2[dataExp2$group=="NMS",]
dataNMS <- dataNMS[c("enteredResponse","word","word1","macron","scoreMorphShortVType","workerId")]
randomScore <- function(list){
list <- read.csv(list);list <- list[,c("item","logprob")]
dataNMS$item <- dataNMS$word1;dataNew <- merge(dataNMS, list, by="item")
dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
return(dataNew)
}
wdScore <- paste0("./MC/morphNBestFixedScore");setwd(wdScore)
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:16){
  files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
  clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
  listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
}
setwd("./../..");wdResult <- paste0("./MC/morphNBestFixedResult");setwd(wdResult);outputAIC <- paste0("NBestFixedListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")

listAIC <- as.data.frame(unlist(listAIC));list <- data.frame(cbind(unlist(listCutOffs)))
listAIC <- cbind(listAIC, list);colnames(listAIC) <- c("AICscore","size")
listAIC$size[(which(listAIC==min(listAIC$AICscore)))] # 1629
min(listAIC$AICscore) # 103363.2
listAIC <- listAIC[,c("size", "AICscore")];colnames(listAIC) <- c("Cutoff","AIC")
# write.table(listAIC,"dataTableS11.txt",sep ="\t", quote=FALSE, row.names=FALSE, col.names=TRUE)

# (8) Repeating the same Monte Carlo analysis with MS participants for morph set sizes N ranging from 0.5k to 3.5k (using cutoffs based on raw frequency of the words they appear in), consisting of the fixed N-best morph types appearing at least 15 times in running speech
dir.create("./MC/msMorphNBestFixedResult")
dataMS <- dataExp2[dataExp2$group=="MS",]
dataMS <- dataMS[c("enteredResponse","word","word1","length","macron","scoreDictShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataMS$item <- dataMS$word1;dataNew <- merge(dataMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
wdScore <- paste0("./MC/morphNBestFixedScore");setwd(wdScore)
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:16){
  files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
  clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
  listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
}
setwd("./../..");wdResult <- paste0("./MC/msMorphNBestFixedResult");setwd(wdResult);outputAIC <- paste0("msMorphNBestFixedListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")

listAIC <- as.data.frame(unlist(listAIC));list <- data.frame(cbind(unlist(listCutOffs)))
listAIC <- cbind(listAIC, list);colnames(listAIC) <- c("AICscore","size")
listAIC$size[(which(listAIC==min(listAIC$AICscore)))] # 3636
min(listAIC$AICscore) # 36718.47
listAIC <- listAIC[,c("size", "AICscore")];colnames(listAIC) <- c("Cutoff","AIC")
# write.table(listAIC,"dataTableS12.txt",sep ="\t", quote=FALSE, row.names=FALSE, col.names=TRUE)

# (9) Monte Carlo analysis with NMS participants for morph set sizes N ranging from 0.5k to 3.5k, considering stimuli as unparsed items, unweighted
dir.create("./MC/morphShortVUnsegSample");dir.create("./MC/morphShortVUnsegPM");dir.create("./MC/morphShortVUnsegPM/aux");dir.create("./MC/morphShortVUnsegScore");dir.create("./MC/morphShortVUnsegResult")
for(i in 1:7){
  directoryName <- paste0("./MC/morphShortVUnsegSample/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphShortVUnsegPM/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphShortVUnsegPM/aux/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphShortVUnsegScore/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
wdSample <- paste0("./MC/morphShortVUnsegSample/size",i*0.5,"k");m <- i*500;setwd(wdSample)
for(j in 1:1000){
randomMorphs <- sample(morphShortVFreq$morph, m, replace = FALSE)
randomMorphs <- gsub(""," ",randomMorphs);randomMorphs <- gsub("^ ","",randomMorphs);randomMorphs <- gsub(" $","",randomMorphs);outputFile <- paste0("randomization_", j, ".txt")
write.table(randomMorphs, outputFile, row.names = FALSE, col.names=FALSE, quote=FALSE)
shellCommand <- paste0("./score-nofreq.sh ./MC/morphShortVUnsegSample/size",i*0.5,"k/randomization_",j,".txt ./stimuli-shortvowels.txt ./MC/morphShortVUnsegPM/size",i*0.5,"k  ./MC/morphShortVUnsegPM/aux/size",i*0.5,"k ./MC/morphShortVUnsegScore/size",i*0.5,"k")
system(shellCommand, intern = TRUE)
}
setwd("./../../..");wdScore <- paste0("./MC/morphShortVUnsegScore/size",i*0.5,"k");setwd(wdScore)
dataNMS <- dataExp2[dataExp2$group=="NMS",]
dataNMS <- dataNMS[c("enteredResponse","word","word1","macron","scoreMorphShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataNMS$item <- dataNMS$word1;dataNew <- merge(dataNMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:1000){
    files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
    clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
    listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
  }
setwd("./../../..");wdResult <- paste0("./MC/morphShortVUnsegResult");setwd(wdResult)
outputAIC <- paste0("morphShortVUnsegSize",i*0.5,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

# (10) Repeating the same Monte Carlo analysis with MS participants for morph set sizes N ranging from 0.5k to 3.5k, considering stimuli as unparsed items, unweighted
dir.create("./MC/msMorphShortVUnsegResult")
for(i in 1:7){
wdScore <- paste0("./MC/morphShortVUnsegScore/size",i*0.5,"k");setwd(wdScore)
dataMS <- dataExp2[dataExp2$group=="MS",]
dataMS <- dataMS[c("enteredResponse","word","word1","length","macron","scoreMorphShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataMS$item <- dataMS$word1;dataNew <- merge(dataMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:1000){
    files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
    clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
    listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
  }
setwd("./../../..");wdResult <- paste0("./MC/msMorphShortVUnsegResult");setwd(wdResult)
outputAIC <- paste0("msMorphShortVUnsegSize",i*0.5,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

# (11) Monte Carlo analysis with NMS participants for morph set sizes N ranging from 0.5k to 3.5k, considering stimuli as unparsed items, weighted by their token frequency in running speech
dir.create("./MC/morphShortVUnsegTokenSample");dir.create("./MC/morphShortVUnsegTokenPM");dir.create("./MC/morphShortVUnsegTokenPM/aux");dir.create("./MC/morphShortVUnsegTokenScore");dir.create("./MC/morphShortVUnsegTokenResult")
for(i in 1:7){
  directoryName <- paste0("./MC/morphShortVUnsegTokenSample/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphShortVUnsegTokenPM/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphShortVUnsegTokenPM/aux/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphShortVUnsegTokenScore/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
wdSample <- paste0("./MC/morphShortVUnsegTokenSample/size",i*0.5,"k");m <- i*500;setwd(wdSample)
for(j in 1:1000){
randomMorphs <- sample(morphShortVFreq$morph, m, replace = FALSE, prob=morphShortVFreq$tokens)
randomMorphs <- gsub(""," ",randomMorphs);randomMorphs <- gsub("^ ","",randomMorphs);randomMorphs <- gsub(" $","",randomMorphs);outputFile <- paste0("randomization_", j, ".txt")
write.table(randomMorphs, outputFile, row.names = FALSE, col.names=FALSE, quote=FALSE)
shellCommand <- paste0("./score-nofreq.sh ./MC/morphShortVUnsegTokenSample/size",i*0.5,"k/randomization_",j,".txt ./stimuli-shortvowels.txt ./MC/morphShortVUnsegTokenPM/size",i*0.5,"k ./MC/morphShortVUnsegTokenPM/aux/size",i*0.5,"k ./MC/morphShortVUnsegTokenScore/size",i*0.5,"k")
system(shellCommand, intern = TRUE)
}
setwd("./../../..");wdScore <- paste0("./MC/morphShortVUnsegTokenScore/size",i*0.5,"k");setwd(wdScore)
dataNMS <- dataExp2[dataExp2$group=="NMS",]
dataNMS <- dataNMS[c("enteredResponse","word","word1","macron","scoreMorphShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataNMS$item <- dataNMS$word1;dataNew <- merge(dataNMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:1000){
    files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
    clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
    listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
  }
setwd("./../../..");wdResult <- paste0("./MC/morphShortVUnsegTokenResult");setwd(wdResult)
outputAIC <- paste0("morphShortVUnsegTokenSize",i*0.5,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

# (12) Repeating the same Monte Carlo analysis with MS participants for morph set sizes N ranging from 0.5k to 3.5k, considering stimuli as unparsed items, weighted by their token frequency in running speech
dir.create("./MC/msMorphShortVUnsegTokenResult")
for(i in 1:7){
wdScore <- paste0("./MC/morphShortVUnsegTokenScore/size",i*0.5,"k");setwd(wdScore)
dataMS <- dataExp2[dataExp2$group=="MS",]
dataMS <- dataMS[c("enteredResponse","word","word1","length","macron","scoreMorphShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataMS$item <- dataMS$word1;dataNew <- merge(dataMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:1000){
    files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
    clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
    listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
  }
setwd("./../../..");wdResult <- paste0("./MC/msMorphShortVUnsegTokenResult");setwd(wdResult)
outputAIC <- paste0("msMorphShortVUnsegTokenSize",i*0.5,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

# (13) Monte Carlo analysis with NMS participants for morph set sizes N ranging from 0.5k to 3.5k, considering stimuli as unparsed items, drawing 1000 random samples of N-best morph types from the morph set weighted by their token frequency in running speech
dir.create("./MC/morphShortVUnsegTokenNBestSample");dir.create("./MC/morphShortVUnsegTokenNBestPM");dir.create("./MC/morphShortVUnsegTokenNBestPM/aux");dir.create("./MC/morphShortVUnsegTokenNBestScore");dir.create("./MC/morphShortVUnsegTokenNBestResult")
for(i in 1:7){
  directoryName <- paste0("./MC/morphShortVUnsegTokenNBestSample/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphShortVUnsegTokenNBestPM/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphShortVUnsegTokenNBestPM/aux/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
  directoryName <- paste0("./MC/morphShortVUnsegTokenNBestScore/size",i*0.5,"k");dir.create(directoryName)
}
for(i in 1:7){
wdSample <- paste0("./MC/morphShortVUnsegTokenNBestSample/size",i*0.5,"k");m <- i*500;setwd(wdSample)
for(j in 1:1000){
morphShortVFreq <- morphShortVFreq[order(runif(nrow(morphShortVFreq))),]
morphShortVFreq <- morphShortVFreq[order(morphShortVFreq$tokens.raw, decreasing=TRUE),]
randomMorphs <- morphShortVFreq$morph[1:m]
randomMorphs <- gsub(""," ",randomMorphs);randomMorphs <- gsub("^ ","",randomMorphs);randomMorphs <- gsub(" $","",randomMorphs);outputFile <- paste0("randomization_", j, ".txt")
write.table(randomMorphs, outputFile, row.names = FALSE, col.names=FALSE, quote=FALSE)
shellCommand <- paste0("./score-nofreq.sh ./MC/morphShortVUnsegTokenNBestSample/size",i*0.5,"k/randomization_",j,".txt ./stimuli-shortvowels.txt ./MC/morphShortVUnsegTokenNBestPM/size",i*0.5,"k ./MC/morphShortVUnsegTokenNBestPM/aux/size",i*0.5,"k ./MC/morphShortVUnsegTokenNBestScore/size",i*0.5,"k")
system(shellCommand, intern = TRUE)
}
setwd("./../../..");wdScore <- paste0("./MC/morphShortVUnsegTokenNBestScore/size",i*0.5,"k");setwd(wdScore)
dataNMS <- dataExp2[dataExp2$group=="NMS",]
dataNMS <- dataNMS[c("enteredResponse","word","word1","macron","scoreMorphShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataNMS$item <- dataNMS$word1;dataNew <- merge(dataNMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:1000){
    files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
    clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
    listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
  }
setwd("./../../..");wdResult <- paste0("./MC/morphShortVUnsegTokenNBestResult");setwd(wdResult)
outputAIC <- paste0("morphShortVUnsegTokenNBestSize",i*0.5,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

# (14) Repeating the same Monte Carlo analysis with MS participants for morph set sizes N ranging from 0.5k to 3.5k, considering stimuli as unparsed items, drawing 1000 random samples of N-best morph types from the morph set weighted by their token frequency in running speech
dir.create("./MC/msMorphShortVUnsegTokenNBestResult")
for(i in 1:7){
wdScore <- paste0("./MC/morphShortVUnsegTokenNBestScore/size",i*0.5,"k");setwd(wdScore)
dataMS <- dataExp2[dataExp2$group=="MS",]
dataMS <- dataMS[c("enteredResponse","word","word1","length","macron","scoreMorphShortVType","workerId")]
randomScore <- function(list){
  list <- read.csv(list);list <- list[,c("item","logprob")]
  dataMS$item <- dataMS$word1;dataNew <- merge(dataMS, list, by="item")
  dataNew$length <- nchar(dataNew$item);dataNew$scoreNor <- dataNew$logprob/(dataNew$length + 1)
  return(dataNew)
}
filenames <- list.files(pattern="*.csv");files <- lapply(filenames, randomScore);listAIC <- list()
for(k in 1:1000){
    files[[k]]$enteredResponse <- as.factor(files[[k]]$enteredResponse)
    clmfit <- clm(enteredResponse ~ scoreNor + macron, data=files[[k]])
    listAIC[[k]] <- AIC(clmfit);message('Regression model of', k,'\n')
  }
setwd("./../../..");wdResult <- paste0("./MC/msMorphShortVUnsegTokenNBestResult");setwd(wdResult)
outputAIC <- paste0("msMorphShortVUnsegTokenNBestSize",i*0.5,"kListAIC.txt")
write.table(unlist(listAIC), outputAIC,row.names = FALSE, col.names=FALSE, quote=FALSE)
setwd("./../..")
}

for(i in 1:7){
  assign(paste0("size",i*0.5,"k"),read.delim(paste0("./MC/morphTypeResult/morphTypeSize",i*0.5,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size0.5k$size <- "0.5k";size1k$size <- "1k";size1.5k$size <- "1.5k";size2k$size <- "2k";size2.5k$size <- "2.5k";size3k$size <- "3k";size3.5k$size <- "3.5k"
morphTypeAIC <- rbind(size0.5k, size1k, size1.5k, size2k, size2.5k, size3k, size3.5k)
morphTypeAIC$type <- "unweighted parsed"

for(i in 1:7){
  assign(paste0("size",i*0.5,"k"),read.delim(paste0("./MC/morphTokenResult/morphTokenSize",i*0.5,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size0.5k$size <- "0.5k";size1k$size <- "1k";size1.5k$size <- "1.5k";size2k$size <- "2k";size2.5k$size <- "2.5k";size3k$size <- "3k";size3.5k$size <- "3.5k"
morphTokenAIC <- rbind(size0.5k, size1k, size1.5k, size2k, size2.5k, size3k, size3.5k)
morphTokenAIC$type <- "frequency-weighted parsed"

for(i in 1:7){
  assign(paste0("size",i*0.5,"k"),read.delim(paste0("./MC/morphTokenNBestResult/morphTokenNBestSize",i*0.5,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size0.5k$size <- "0.5k";size1k$size <- "1k";size1.5k$size <- "1.5k";size2k$size <- "2k";size2.5k$size <- "2.5k";size3k$size <- "3k";size3.5k$size <- "3.5k"
morphTokenNBestAIC <- rbind(size0.5k, size1k, size1.5k, size2k, size2.5k, size3k, size3.5k)
morphTokenNBestAIC$type <- "N highest-frequency parsed"

for(i in 1:7){
  assign(paste0("size",i*0.5,"k"),read.delim(paste0("./MC/morphShortVUnsegResult/morphShortVUnsegSize",i*0.5,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size0.5k$size <- "0.5k";size1k$size <- "1k";size1.5k$size <- "1.5k";size2k$size <- "2k";size2.5k$size <- "2.5k";size3k$size <- "3k";size3.5k$size <- "3.5k"
morphShortVUnsegAIC <- rbind(size0.5k, size1k, size1.5k, size2k, size2.5k, size3k, size3.5k)
morphShortVUnsegAIC$type <- "unweighted unparsed"

for(i in 1:7){
  assign(paste0("size",i*0.5,"k"),read.delim(paste0("./MC/morphShortVUnsegTokenResult/morphShortVUnsegTokenSize",i*0.5,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size0.5k$size <- "0.5k";size1k$size <- "1k";size1.5k$size <- "1.5k";size2k$size <- "2k";size2.5k$size <- "2.5k";size3k$size <- "3k";size3.5k$size <- "3.5k"
morphShortVUnsegTokenAIC <- rbind(size0.5k, size1k, size1.5k, size2k, size2.5k, size3k, size3.5k)
morphShortVUnsegTokenAIC$type <- "frequency-weighted unparsed"

for(i in 1:7){
  assign(paste0("size",i*0.5,"k"),read.delim(paste0("./MC/morphShortVUnsegTokenNBestResult/morphShortVUnsegTokenNBestSize",i*0.5,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size0.5k$size <- "0.5k";size1k$size <- "1k";size1.5k$size <- "1.5k";size2k$size <- "2k";size2.5k$size <- "2.5k";size3k$size <- "3k";size3.5k$size <- "3.5k"
morphShortVUnsegTokenNBestAIC <- rbind(size0.5k, size1k, size1.5k, size2k, size2.5k, size3k, size3.5k)
morphShortVUnsegTokenNBestAIC$type <- "N highest-frequency unparsed"

nmsMorphAIC <- rbind(morphTypeAIC, morphTokenAIC, morphTokenNBestAIC, morphShortVUnsegAIC, morphShortVUnsegTokenAIC, morphShortVUnsegTokenNBestAIC)

for(i in 1:7){
  assign(paste0("size",i*0.5,"k"),read.delim(paste0("./MC/msMorphTypeResult/msMorphTypeSize",i*0.5,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size0.5k$size <- "0.5k";size1k$size <- "1k";size1.5k$size <- "1.5k";size2k$size <- "2k";size2.5k$size <- "2.5k";size3k$size <- "3k";size3.5k$size <- "3.5k"
msMorphTypeAIC <- rbind(size0.5k, size1k, size1.5k, size2k, size2.5k, size3k, size3.5k)
msMorphTypeAIC$type <- "unweighted parsed"

for(i in 1:7){
  assign(paste0("size",i*0.5,"k"),read.delim(paste0("./MC/msMorphTokenResult/msMorphTokenSize",i*0.5,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size0.5k$size <- "0.5k";size1k$size <- "1k";size1.5k$size <- "1.5k";size2k$size <- "2k";size2.5k$size <- "2.5k";size3k$size <- "3k";size3.5k$size <- "3.5k"
msMorphTokenAIC <- rbind(size0.5k, size1k, size1.5k, size2k, size2.5k, size3k, size3.5k)
msMorphTokenAIC$type <- "frequency-weighted parsed"

for(i in 1:7){
  assign(paste0("size",i*0.5,"k"),read.delim(paste0("./MC/msMorphTokenNBestResult/msMorphTokenNBestSize",i*0.5,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size0.5k$size <- "0.5k";size1k$size <- "1k";size1.5k$size <- "1.5k";size2k$size <- "2k";size2.5k$size <- "2.5k";size3k$size <- "3k";size3.5k$size <- "3.5k"
msMorphTokenNBestAIC <- rbind(size0.5k, size1k, size1.5k, size2k, size2.5k, size3k, size3.5k)
msMorphTokenNBestAIC$type <- "N highest-frequency parsed"

for(i in 1:7){
  assign(paste0("size",i*0.5,"k"),read.delim(paste0("./MC/msMorphShortVUnsegResult/msMorphShortVUnsegSize",i*0.5,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size0.5k$size <- "0.5k";size1k$size <- "1k";size1.5k$size <- "1.5k";size2k$size <- "2k";size2.5k$size <- "2.5k";size3k$size <- "3k";size3.5k$size <- "3.5k"
msMorphShortVUnsegAIC <- rbind(size0.5k, size1k, size1.5k, size2k, size2.5k, size3k, size3.5k)
msMorphShortVUnsegAIC$type <- "unweighted unparsed"

for(i in 1:7){
  assign(paste0("size",i*0.5,"k"),read.delim(paste0("./MC/msMorphShortVUnsegTokenResult/msMorphShortVUnsegTokenSize",i*0.5,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size0.5k$size <- "0.5k";size1k$size <- "1k";size1.5k$size <- "1.5k";size2k$size <- "2k";size2.5k$size <- "2.5k";size3k$size <- "3k";size3.5k$size <- "3.5k"
msMorphShortVUnsegTokenAIC <- rbind(size0.5k, size1k, size1.5k, size2k, size2.5k, size3k, size3.5k)
msMorphShortVUnsegTokenAIC$type <- "frequency-weighted unparsed"

for(i in 1:7){
  assign(paste0("size",i*0.5,"k"),read.delim(paste0("./MC/msMorphShortVUnsegTokenNBestResult/msMorphShortVUnsegTokenNBestSize",i*0.5,"kListAIC.txt"), sep ="\t", header = FALSE))
}
size0.5k$size <- "0.5k";size1k$size <- "1k";size1.5k$size <- "1.5k";size2k$size <- "2k";size2.5k$size <- "2.5k";size3k$size <- "3k";size3.5k$size <- "3.5k"
msMorphShortVUnsegTokenNBestAIC <- rbind(size0.5k, size1k, size1.5k, size2k, size2.5k, size3k, size3.5k)
msMorphShortVUnsegTokenNBestAIC$type <- "N highest-frequency unparsed"

msMorphAIC <- rbind(msMorphTypeAIC, msMorphTokenAIC, msMorphTokenNBestAIC, msMorphShortVUnsegAIC,msMorphShortVUnsegTokenAIC, msMorphShortVUnsegTokenNBestAIC)

# write.table(nmsMorphAIC,"dataFigS8NMS.txt",sep ="\t", quote=FALSE, row.names=FALSE, col.names=TRUE)
# write.table(msMorphAIC,"dataFigS8MS.txt",sep ="\t", quote=FALSE, row.names=FALSE, col.names=TRUE)

# Run ordinal regression models with all morphs
clmfitMorphNMS <- clm(enteredResponse ~ scoreMorphShortVType + macron, data=dataNMS)
clmfitMorphMS <- clm(enteredResponse ~ scoreMorphShortVType + macron, data=dataMS)
# saveRDS(clmfitMorphNMS, file = "morphNMS.rds")
# saveRDS(clmfitMorphMS, file = "morphMS.rds")
```

### Comparing AIC scores using cutoffs based on raw frequency of the words morphs appear in
```{r Table S11-12, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE}
TableS11 <- read.delim("./dataTableS11.txt", sep ="\t", header = TRUE)
kable(TableS11, align="c", caption="Table S12: Comparing AIC scores with NMS participants, using cutoffs based on raw frequency of the words morphs appear in")

TableS12 <- read.delim("./dataTableS12.txt", sep ="\t", header = TRUE)
kable(TableS12, align="c", caption="Table S13: Comparing AIC scores with MS participants, using cutoffs based on raw frequency of the words morphs appear in")
```

### Code for plotting Fig. 4
```{r Fig. 4, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE, fig.width=13, fig.height=7.5, fig.cap="Figure 4: Density plot of AIC scores for morph random samples"}
figS8NMS <- read.delim("./dataFigS8NMS.txt", sep ="\t", header = TRUE)
figS8NMS$size <- ordered(figS8NMS$size, levels = c("0.5k","1k","1.5k","2k","2.5k","3k","3.5k"))
fullMorphsNMS <- readRDS("./morphNMS.rds");fullMorphsAICNMS <- AIC(fullMorphsNMS)
fullDictNMS <- readRDS("./fullDictNMS.rds");fullDictAICNMS <- AIC(fullDictNMS)
levels(figS8NMS$type) <- c("frequency-weighted parsed", "frequency-weighted unparsed", "N highest-frequency parsed", "N highest-frequency unparsed", "unweighted parsed", "unweighted unparsed")

figS8NMS.summary <- figS8NMS %>%
  group_by(size, type) %>%
  summarise(
    mean.AIC = mean(V1),
    lower.AIC = quantile(V1, probs=c(0.025)),
    upper.AIC = quantile(V1, probs=c(0.975))
  )

fig6A <- ggplot(subset(figS8NMS.summary, type %in% c("frequency-weighted parsed", "N highest-frequency parsed", "unweighted parsed")), aes(x=as.numeric(size) * 0.5, y=mean.AIC, ymin=lower.AIC, ymax=upper.AIC)) +
  geom_errorbar(aes(color=type), position=position_dodge(width=0.2), size=1) +
  geom_line(aes(color=type), position=position_dodge(width=0.2), size=1, alpha=0.5) +
  geom_hline(aes(yintercept=fullDictAICNMS, linetype="Full dictionary (18k)"), color="gray30", size=1) +   
  geom_hline(aes(yintercept=fullMorphsAICNMS, linetype="Full morph set (3.6k)"), color="black", size=1) +
  geom_point(aes(fill=type), shape=21, position=position_dodge(width=0.2), size=3) +
  labs(title="NMS participants (parsed)",x="Morph size", y="AIC score") + 
  theme_classic() + 
  scale_linetype_manual(values=c("Full morph set (3.6k)"="dotted",
                                 "Full dictionary (18k)"="dashed")) +  
  scale_x_continuous(breaks=seq(from=0.5, to=3.5, by=0.5), labels=levels(figS8NMS.summary$size)) +
  theme(
    plot.title=element_text(hjust=0.5, size=15),
    legend.text=element_text(size=10),
    legend.title = element_blank()) + coord_cartesian(ylim=c(103200, 105200))

fig6B <- ggplot(subset(figS8NMS.summary, type %in% c("frequency-weighted unparsed", "N highest-frequency unparsed", "unweighted unparsed")), aes(x=as.numeric(size) * 0.5, y=mean.AIC, ymin=lower.AIC, ymax=upper.AIC)) +
  geom_errorbar(aes(color=type), position=position_dodge(width=0.2), size=1) +
  geom_line(aes(color=type), position=position_dodge(width=0.2), size=1, alpha=0.5) +
  geom_hline(aes(yintercept=fullDictAICNMS, linetype="Full dictionary (18k)"), color="gray30", size=1) +   
  geom_hline(aes(yintercept=fullMorphsAICNMS, linetype="Full morph set (3.6k)"), color="black", size=1) +
  geom_point(aes(fill=type), shape=21, position=position_dodge(width=0.2), size=3) +
  labs(title="NMS participants (unparsed)",x="Morph size", y="AIC score") + 
  theme_classic() + 
  scale_linetype_manual(values=c("Full morph set (3.6k)"="dotted",
                                 "Full dictionary (18k)"="dashed")) +  
  scale_x_continuous(breaks=seq(from=0.5, to=3.5, by=0.5), labels=levels(figS8NMS.summary$size)) +
  theme(
    plot.title=element_text(hjust=0.5, size=15),
    legend.text=element_text(size=10),
    legend.title = element_blank()) + coord_cartesian(ylim=c(103200, 105200))

figS8MS <- read.delim("./dataFigS8MS.txt", sep ="\t", header = TRUE)
figS8MS$size <- ordered(figS8MS$size, levels = c("0.5k","1k","1.5k","2k","2.5k","3k","3.5k"))
fullMorphsMS <- readRDS("./morphMS.rds");fullMorphsAICMS <- AIC(fullMorphsMS)
fullDictMS <- readRDS("./fullDictMS.rds");fullDictAICMS <- AIC(fullDictMS)
levels(figS8MS$type) <- c("frequency-weighted parsed", "frequency-weighted unparsed", "N highest-frequency parsed", "N highest-frequency unparsed", "unweighted parsed", "unweighted unparsed")

figS8MS.summary <- figS8MS %>%
  group_by(size, type) %>%
  summarise(
    mean.AIC = mean(V1),
    lower.AIC = quantile(V1, probs=c(0.025)),
    upper.AIC = quantile(V1, probs=c(0.975))
  )

fig6C <- ggplot(subset(figS8MS.summary, type %in% c("frequency-weighted parsed", "N highest-frequency parsed", "unweighted parsed")), aes(x=as.numeric(size) * 0.5, y=mean.AIC, ymin=lower.AIC, ymax=upper.AIC)) +
  geom_errorbar(aes(color=type), position=position_dodge(width=0.2), size=1) +
  geom_line(aes(color=type), position=position_dodge(width=0.2), size=1, alpha=0.5) +
  geom_hline(aes(yintercept=fullDictAICMS, linetype="Full dictionary (18k)"), color="gray30", size=1) +   
  geom_hline(aes(yintercept=fullMorphsAICMS, linetype="Full morph set (3.6k)"), color="black", size=1) +
  geom_point(aes(fill=type), shape=21, position=position_dodge(width=0.2), size=3) +
  labs(title="MS participants (parsed)",x="Morph size", y="AIC score") + 
  theme_classic() + 
  scale_linetype_manual(values=c("Full morph set (3.6k)"="dotted",
                                 "Full dictionary (18k)"="dashed")) +  
  scale_x_continuous(breaks=seq(from=0.5, to=3.5, by=0.5), labels=levels(figS8MS.summary$size)) +
  theme(
    plot.title=element_text(hjust=0.5, size=15),
    legend.text=element_text(size=10),
    legend.title = element_blank()) + coord_cartesian(ylim=c(36450, 37100))

fig6D <- ggplot(subset(figS8MS.summary, type %in% c("frequency-weighted unparsed", "N highest-frequency unparsed", "unweighted unparsed")), aes(x=as.numeric(size) * 0.5, y=mean.AIC, ymin=lower.AIC, ymax=upper.AIC)) +
  geom_errorbar(aes(color=type), position=position_dodge(width=0.2), size=1) +
  geom_line(aes(color=type), position=position_dodge(width=0.2), size=1, alpha=0.5) +
  geom_hline(aes(yintercept=fullDictAICMS, linetype="Full dictionary (18k)"), color="gray30", size=1) +   
  geom_hline(aes(yintercept=fullMorphsAICMS, linetype="Full morph set (3.6k)"), color="black", size=1) +
  geom_point(aes(fill=type), shape=21, position=position_dodge(width=0.2), size=3) +
  labs(title="MS participants (unparsed)",x="Morph size", y="AIC score") + 
  theme_classic() + 
  scale_linetype_manual(values=c("Full morph set (3.6k)"="dotted",
                                 "Full dictionary (18k)"="dashed")) +  
  scale_x_continuous(breaks=seq(from=0.5, to=3.5, by=0.5), labels=levels(figS8MS.summary$size)) +
  theme(
    plot.title=element_text(hjust=0.5, size=15),
    legend.text=element_text(size=10),
    legend.title = element_blank()) + coord_cartesian(ylim=c(36450, 37100))

multiplot(fig6A, fig6C, fig6B,fig6D, cols=2)
```

## Comparing AIC scores with NMS participants for model selection 

  - *scoreDictShortVType* is the phonotactic score across word types in the dictionary ignoring vowel length distinction.
  - *scoreNBestFixed* is the phonotactic score from 3470 most frequent word types with the lowest AIC score obtained using cutoffs based on raw frequency.
  - *scoreMorphShortVType* is the phonotactic score across morph types derived from words in the dictionary ignoring vowel length distinctions.
  - *scoreMorphNBestFixed* is the phonotactic score from 1629 morph types with the highest token frequency in running speech with the lowest AIC, obtained using cutoffs based on raw frequency.
  - *scoreMorphNBestWord* is the phonotactic score derived from 1409 morphs which occur within 3470 words in the corpora.
  - *scoreMorphShortVWord* is the phonotactic score from 1303 morphs weighted by 3470 most frequent word types in the dictionary they appear in.

```{r Best Model For NMS, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE}
# Ordinal mixed-effects model with the phonotactics from the phonotactic score obtained across word types in the dictionary ignoring all vowel length distinctions.   
# modelDictShortVTypeNMS <- clmm(enteredResponse ~ c.(scoreDictShortVType) + macron + (1 + c.(scoreDictShortVType) + macron | workerId) + (1 | word), dataNMS)
# saveRDS(modelDictShortVTypeNMS, file = "modelDictShortVTypeNMS.rds")
modelDictShortVTypeNMS <- readRDS("./modelDictShortVTypeNMS.rds")

# Ordinal mixed-effects model with the phonotactics from the 3470 most frequent types (with the lowest AIC using cutoffs based on raw frequency)
# scoreWordNMS <- read_csv("./MC/NBestFixedScore/NBestFixedSample3470.csv")
# scoreWordNMS$scoreWordNMS <- scoreWordNMS$logprob/(scoreWordNMS$length + 1);scoreWordNMS <- scoreWordNMS[,c("item","scoreWordNMS")]
# dataNMS$item <- dataNMS$word1;dataNew <- merge(dataNMS, scoreWordNMS, by="item")
# modelBestFixedNMS <- clmm(enteredResponse ~ c.(scoreWordNMS) + macron + (1 + c.(scoreWordNMS) + macron | workerId) + (1 | word), dataNew)
# setwd("/Users/yoonmi/Documents/GitHub/SuppInfoProtoLexiconNew")
# saveRDS(modelBestFixedNMS, file = "modelBestFixedNMS.rds")
modelBestFixedNMS <- readRDS("./modelBestFixedNMS.rds")

# Ordinal mixed-effects model with the phonotactics from the phonotactic score obtained across morph types derived from words in the dictionary ignoring vowel length distinctions, unweighted
# modelMorphShortVTypeNMS <- clmm(enteredResponse ~ c.(scoreMorphShortVType) + macron + (1 + c.(scoreMorphShortVType) + macron | workerId) + (1 | word), dataNMS)
# saveRDS(modelMorphShortVTypeNMS, file = "modelMorphShortVTypeNMS.rds")
modelMorphShortVTypeNMS <- readRDS("./modelMorphShortVTypeNMS.rds")

# Ordinal mixed-effects model with the phonotactics from the 1629 morph types which have highest token frequency in running speech  (with the lowest AIC using cutoffs based on raw frequency)
# scoreMorphNBestFixedNMS <- read_csv("./MC/morphNBestFixedScore/morphNBestFixedSample1629.csv")
# scoreMorphNBestFixedNMS$scoreMorphNBestFixedNMS <- scoreMorphNBestFixedNMS$logprob/(scoreMorphNBestFixedNMS$length + 1)
# scoreMorphNBestFixedNMS <- scoreMorphNBestFixedNMS[,c("item","scoreMorphNBestFixedNMS")]
# dataNMS$item <- dataNMS$word1;dataNew <- merge(dataNMS, scoreMorphNBestFixedNMS, by="item")
# modelMorphNBestFixedNMS <- clmm(enteredResponse ~ c.(scoreMorphNBestFixedNMS) + macron + (1 + c.(scoreMorphNBestFixedNMS) + macron | workerId) + (1 | word), dataNew)
# saveRDS(modelMorphNBestFixedNMS, file = "modelMorphNBestFixedNMS.rds")
modelMorphNBestFixedNMS <- readRDS("./modelMorphNBestFixedNMS.rds")

# Phonotactics derived from the 1409 morphs that occur within the 3470 words appearing 4+times in the corpora 
# scoreMorphNBestWordNMS <- read_csv("./MC/morphNBestWordScore/NBestWordMorphSample.csv")
# scoreMorphNBestWordNMS$scoreMorphNBestWordNMS <- scoreMorphNBestWordNMS$logprob/(scoreMorphNBestWordNMS$length + 1)
# scoreMorphNBestWordNMS <- scoreMorphNBestWordNMS[,c("item","scoreMorphNBestWordNMS")]
# dataNMS$item <- dataNMS$word1;dataNew <- merge(dataNMS, scoreMorphNBestWordNMS, by="item")
# modelMorphNBestWordNMS <- clmm(enteredResponse ~ c.(scoreMorphNBestWordNMS) + macron + (1 + c.(scoreMorphNBestWordNMS) + macron | workerId) + (1 | word), dataNew)
# saveRDS(modelMorphNBestWordNMS, file = "modelMorphNBestWordNMS.rds")
modelMorphNBestWordNMS <- readRDS("./modelMorphNBestWordNMS.rds")

# Phonotactics derived from 1303 morphs weighted by 3470 words in the dictionary they appear in, considering stimuli as parsed items
# scoreMorphShortVWordNMS <- read_csv("./MC/morphShortVWords/scores/morphs_3470.csv")
# scoreMorphShortVWordNMS$scoreMorphShortVWordNMS <- scoreMorphShortVWordNMS$logprob/(scoreMorphShortVWordNMS$length + 1)
# scoreMorphShortVWordNMS <- scoreMorphShortVWordNMS[,c("item","scoreMorphShortVWordNMS")]
# dataNMS$item <- dataNMS$word1;dataNew <- merge(dataNMS, scoreMorphShortVWordNMS, by="item")
# modelMorphShortVWordNMS <- clmm(enteredResponse ~ c.(scoreMorphShortVWordNMS) + macron + (1 + c.(scoreMorphShortVWordNMS) + macron | workerId) + (1 | word), dataNew)
# saveRDS(modelMorphShortVWordNMS, file = "modelMorphShortVWordNMS.rds")
modelMorphShortVWordNMS <- readRDS("./modelMorphShortVWordNMS.rds")

Score <- c("scoreDictShortVType","scoreNBestFixed","scoreMorphShortVType","scoreMorphNBestFixed","scoreMorphNBestWord","scoreMorphShortVWord")
AIC <- c(AIC(modelDictShortVTypeNMS),AIC(modelBestFixedNMS),AIC(modelMorphShortVTypeNMS),AIC(modelMorphNBestFixedNMS),AIC(modelMorphNBestWordNMS),AIC(modelMorphShortVWordNMS))
aicNMST <- data.frame(Score,AIC)
kable(aicNMST, align="c", caption="Table S14: Comparing AIC scores with NMS participants for model selection.")
```

### Self-reported exposure to Māori 
NMS' self-reported exposure to Māori is added as an additional predictor to the best ordinal mixed-effects model presented in Table S14.

```{r MaoriExpo, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE}
# Self-reported exposure to Māori (NMS participants only) 
# scoreMorphNBestFixedNMS <- read_csv("./MC/morphNBestFixedScore/morphNBestFixedSample1629.csv")
#scoreMorphNBestFixedNMS$scoreMorphNBestFixedNMS <- scoreMorphNBestFixedNMS$logprob/(scoreMorphNBestFixedNMS$length + 1)
# scoreMorphNBestFixedNMS <- scoreMorphNBestFixedNMS[,c("item","scoreMorphNBestFixedNMS")]
# dataNMS$item <- dataNMS$word1;dataNew <- merge(dataNMS, scoreMorphNBestFixedNMS, by="item")
# modelExpoNMS <- clmm(enteredResponse ~ (c.(scoreMorphNBestFixedNMS) + macron) * c.(maoriExpo) + (1 + c.(scoreMorphNBestFixedNMS) + macron | workerId) + (1 + c.(maoriExpo) | word), dataNew)
# saveRDS(modelExpoNMS, file = "modelExpoNMS.rds")
modelExpoNMS <- readRDS("./modelExpoNMS.rds")
kable(clm_table(modelExpoNMS), digits=3, caption="Table S15: Ordinal mixed-effects model of well-formedness ratings including NMS' self-reported exposure to Māori")
```

# Post-questionnaire
1. How well are you able to speak Māori?<br />
☐ Very well (I can talk about almost anything in Māori)<br />
☐ Well (I can talk about many things in Māori)<br />
☐ Fairly well (I can talk about some things in Māori)<br />
☐ Not very well (I can only talk about simple/basic things in Māori)<br />
☐ No more than a few words or phrases<br />
☐ Not at all

2. How well are you able to understand/read Māori?<br />
☐ Very well (I can understand almost anything said/written in Māori)<br />
☐ Well (I can understand many things said/written in Māori)<br />
☐ Fairly well (I can understand some things said/written in Māori)<br />
☐ Not very well (I can only understand simple/basic things said/written in Māori) <br />
☐ No more than a few words or phrases<br />
☐ Not at all

3. Which age group do you belong to?<br /> 
☐ 18 - 29<br />
☐ 30 - 39<br />
☐ 40 - 49<br />
☐ 50 - 59<br />
☐ +60

4. Please state your gender:

5. Please state your ethnicity:

6. Your highest education is:<br /> 
☐ High school<br />
☐ Undergraduate degree<br />
☐ Graduate degree<br />

7. How often do you think you are exposed to the Māori language in your daily life, by means of Māori radio, Māori TV, online media? (only relevant for fluent Māori speakers and non-fluent Māori speakers of New Zealand English)<br />
☐ Less than once a year<br />
☐ Less than once a month<br />
☐ Less than once a week<br />
☐ Less than once a day<br />
☐ Multiple times a day<br />

8. How often do you think you are exposed to Māori language in your daily life, in conversation at work, at home, in social settings? (only relevant for fluent Māori speakers and non-fluent Māori speakers of New Zealand English)<br />
☐ Less than once a year<br />
☐ Less than once a month<br /> 
☐ Less than once a week<br />
☐ Less than once a day<br /> 
☐ Multiple times a day<br />

9. In the past five years, have you had any children living with you who have attended preschool or primary school in New Zealand? (only relevant for fluent Māori speakers and non-fluent Māori speakers of New Zealand English)<br />
☐ Yes<br />
☐ No<br />

10. Please tick all boxes that apply.<br />
☐ I can give a mihi in Māori.<br />
☐ I can sing a few songs in Māori.<br />
☐ I can sing the NZ national anthem in Māori.<br />
☐ I know how to say some basic phrases (e.g. My name is..., I'm from...) in Māori.<br /> 
☐ I know how to say some commands (e.g. Sit down / Come here) in Māori.<br />
☐ I know how to say some greetings in Māori.<br />
☐ I know how to say some numbers in Māori.<br /> 
☐ I know how to say some body parts in Māori.<br /> 
☐ I know how to say some colors in Māori.<br />

11. What region of New Zealand do you live in currently? (Please choose ``overseas" if you are living outside of New Zealand.) (only relevant for fluent Māori speakers and non-fluent Māori speakers of New Zealand English)<br />
☐ Northland<br />
☐ Auckland<br />
☐ Waikato<br />
☐ Bay of Plenty<br />
☐ Gisborne<br />
☐ Hawke's Bay<br />
☐ Taranaki<br />
☐ Wanganui<br />
☐ Manawatu<br />
☐ Wairarapa<br />
☐ Wellington<br />
☐ Nelson Bays<br />
☐ Marlborough<br />
☐ West Coast<br />
☐ Canterbury<br />
☐ Timaru - Oamaru<br /> 
☐ Otago<br />
☐ Southland<br />
☐ Overseas<br />

12. How long have you been living there? (only relevant for fluent Māori speakers and non-fluent Māori speakers of New Zealand English)

13. Please state your first language (the language you speak/use most of your time).

14. What country were you living in when you first learned this language?

15. Please list any other languages that you can speak fluently:

16. Have you ever lived in Hawaii? <br />
☐ Yes<br />
☐ No

17. Have you ever lived in New Zealand (only relevant for non-fluent Māori speakers of American English)?<br />
☐ Yes<br />
☐ No

18. Do you speak/understand any Polynesian languages such as Hawaiian, Tahitian, Sāmoan, or Tongan?<br />
☐ Yes<br />
☐ No

19. If you replied yes to question 18, please state the language you know.

20. Do you have a history of any speech or language impairments that you are aware of?<br /> 
☐ Yes<br />
☐ No